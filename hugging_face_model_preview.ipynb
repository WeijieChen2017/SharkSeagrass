{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WXC321/Downloads/github/SharkSeagrass/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/WXC321/Downloads/github/SharkSeagrass/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(urlopen(\n",
    "    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "))\n",
    "\n",
    "model = timm.create_model(\n",
    "    'densenet201.tv_in1k',\n",
    "    pretrained=True,\n",
    "    num_classes=0,  # remove classifier nn.Linear\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm .data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # output is (batch_size, num_features) shaped tensor\n",
    "\n",
    "# or equivalently (without needing to set num_classes=0)\n",
    "\n",
    "output = model.forward_features(transforms(img).unsqueeze(0))\n",
    "# output is unpooled, a (1, 1920, 7, 7) shaped tensor\n",
    "\n",
    "output = model.forward_head(output, pre_logits=True)\n",
    "# output is a (1, num_features) shaped tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "torch.Size([1, 1920])\n"
     ]
    }
   ],
   "source": [
    "print(img.size)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 1920, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "img_input = transforms(img).unsqueeze(0)\n",
    "print(img_input.shape)\n",
    "img_output = model.forward_features(img_input)\n",
    "print(img_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "class DenseNetWithoutPooling(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            growth_rate=32,\n",
    "            block_config=(6, 12, 24, 16),\n",
    "            num_classes=1000,\n",
    "            in_chans=3,\n",
    "            global_pool=None,  # Set to None to remove global pooling\n",
    "            bn_size=4,\n",
    "            stem_type='',\n",
    "            act_layer='relu',\n",
    "            norm_layer='batchnorm2d',\n",
    "            aa_layer=None,\n",
    "            drop_rate=0.,\n",
    "            proj_drop_rate=0.,\n",
    "            memory_efficient=False,\n",
    "            aa_stem_only=True,\n",
    "    ):\n",
    "        super(DenseNetWithoutPooling, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        norm_layer = get_norm_act_layer(norm_layer, act_layer=act_layer)\n",
    "\n",
    "        # Stem\n",
    "        deep_stem = 'deep' in stem_type  # 3x3 deep stem\n",
    "        num_init_features = growth_rate * 2\n",
    "        if aa_layer is None:\n",
    "            # Replace pooling with Identity layer (no-op)\n",
    "            stem_pool = nn.Identity()\n",
    "        else:\n",
    "            stem_pool = nn.Sequential(*[\n",
    "                nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                aa_layer(channels=num_init_features, stride=2)])\n",
    "        if deep_stem:\n",
    "            stem_chs_1 = stem_chs_2 = growth_rate\n",
    "            if 'tiered' in stem_type:\n",
    "                stem_chs_1 = 3 * (growth_rate // 4)\n",
    "                stem_chs_2 = num_init_features if 'narrow' in stem_type else 6 * (growth_rate // 4)\n",
    "            self.features = nn.Sequential(OrderedDict([\n",
    "                ('conv0', nn.Conv2d(in_chans, stem_chs_1, 3, stride=2, padding=1, bias=False)),\n",
    "                ('norm0', norm_layer(stem_chs_1)),\n",
    "                ('conv1', nn.Conv2d(stem_chs_1, stem_chs_2, 3, stride=1, padding=1, bias=False)),\n",
    "                ('norm1', norm_layer(stem_chs_2)),\n",
    "                ('conv2', nn.Conv2d(stem_chs_2, num_init_features, 3, stride=1, padding=1, bias=False)),\n",
    "                ('norm2', norm_layer(num_init_features)),\n",
    "                ('pool0', stem_pool),  # Replaced pool with Identity layer\n",
    "            ]))\n",
    "        else:\n",
    "            self.features = nn.Sequential(OrderedDict([\n",
    "                ('conv0', nn.Conv2d(in_chans, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "                ('norm0', norm_layer(num_init_features)),\n",
    "                ('pool0', stem_pool),  # Replaced pool with Identity layer\n",
    "            ]))\n",
    "        self.feature_info = [\n",
    "            dict(num_chs=num_init_features, reduction=2, module=f'features.norm{2 if deep_stem else 0}')]\n",
    "        current_stride = 4\n",
    "\n",
    "        # DenseBlocks\n",
    "        num_features = num_init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = DenseBlock(\n",
    "                num_layers=num_layers,\n",
    "                num_input_features=num_features,\n",
    "                bn_size=bn_size,\n",
    "                growth_rate=growth_rate,\n",
    "                norm_layer=norm_layer,\n",
    "                drop_rate=proj_drop_rate,\n",
    "                grad_checkpointing=memory_efficient,\n",
    "            )\n",
    "            module_name = f'denseblock{(i + 1)}'\n",
    "            self.features.add_module(module_name, block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            transition_aa_layer = None if aa_stem_only else aa_layer\n",
    "            if i != len(block_config) - 1:\n",
    "                self.feature_info += [\n",
    "                    dict(num_chs=num_features, reduction=current_stride, module='features.' + module_name)]\n",
    "                current_stride *= 2\n",
    "                trans = DenseTransition(\n",
    "                    num_input_features=num_features,\n",
    "                    num_output_features=num_features // 2,\n",
    "                    norm_layer=norm_layer,\n",
    "                    aa_layer=transition_aa_layer,\n",
    "                )\n",
    "                self.features.add_module(f'transition{i + 1}', trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "        # Final batch norm\n",
    "        self.features.add_module('norm5', norm_layer(num_features))\n",
    "\n",
    "        self.feature_info += [dict(num_chs=num_features, reduction=current_stride, module='features.norm5')]\n",
    "        self.num_features = self.head_hidden_size = num_features\n",
    "\n",
    "        # Global Pooling & Classifier removed\n",
    "        self.global_pool = nn.Identity()  # No pooling\n",
    "        self.head_drop = nn.Dropout(drop_rate)\n",
    "        self.classifier = nn.Identity()  # No classifier for feature extraction\n",
    "\n",
    "        # Official init from torch repo.\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass without pooling\n",
    "        x = self.features(x)\n",
    "        x = self.global_pool(x)  # Identity, no global pooling\n",
    "        x = self.head_drop(x)\n",
    "        x = self.classifier(x)  # Identity, no classifier\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
