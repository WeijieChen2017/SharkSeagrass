{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is changed from the orginal code and modified by ChatGPT from\n",
    "https://github.com/thuanz123/enhancing-transformers/blob/1778fc497ea11ed2cef134404f99d4d6b921cda9/enhancing/modules/stage1/layers.py\n",
    "\"\"\"\n",
    "\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Enhancing Transformers\n",
    "# Copyright (c) 2022 Thuan H. Nguyen. All Rights Reserved.\n",
    "# Licensed under the MIT License [see LICENSE for details]\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Modified from Taming Transformers (https://github.com/CompVis/taming-transformers)\n",
    "# Copyright (c) 2020 Patrick Esser and Robin Rombach and BjÃ¶rn Ommer. All Rights Reserved.\n",
    "# ------------------------------------------------------------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import PIL\n",
    "import math\n",
    "import torch\n",
    "import importlib\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from functools import partial\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from typing import List, Tuple, Dict, Any, Optional, Union\n",
    "from omegaconf import OmegaConf\n",
    "from collections import OrderedDict\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_size = 64\n",
    "pix_dim = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localhost 8000 is running.\n"
     ]
    }
   ],
   "source": [
    "# verify the localhost 8000 is running\n",
    "import requests\n",
    "try:\n",
    "    r = requests.get('http://localhost:8000')\n",
    "    assert r.status_code == 200\n",
    "    print('Localhost 8000 is running.')\n",
    "except:\n",
    "    raise Exception('Please make sure the localhost 8000 is running. Run `python -m http.server` in the root directory of this repo.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    assert embed_dim % 2 == 0\n",
    "    omega = np.arange(embed_dim // 2, dtype=float)\n",
    "    omega /= embed_dim / 2.\n",
    "    omega = 1. / 10000**omega  # (D/2,)\n",
    "\n",
    "    pos = pos.reshape(-1)  # (M,)\n",
    "    out = np.einsum('m,d->md', pos, omega)  # (M, D/2), outer product\n",
    "\n",
    "    emb_sin = np.sin(out) # (M, D/2)\n",
    "    emb_cos = np.cos(out) # (M, D/2)\n",
    "\n",
    "    emb = np.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
    "    assert embed_dim % 3 == 0\n",
    "\n",
    "    emb_d = get_1d_sincos_pos_embed_from_grid(embed_dim // 3, grid[0])  # (D*H*W, D/3)\n",
    "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 3, grid[1])  # (D*H*W, D/3)\n",
    "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 3, grid[2])  # (D*H*W, D/3)\n",
    "\n",
    "    emb = np.concatenate([emb_d, emb_h, emb_w], axis=1) # (D*H*W, D)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3d_sincos_pos_embed(embed_dim, grid_size):\n",
    "    grid_size = (grid_size, grid_size, grid_size) if type(grid_size) != tuple else grid_size\n",
    "    grid_d = np.arange(grid_size[0], dtype=np.float32)\n",
    "    grid_h = np.arange(grid_size[1], dtype=np.float32)\n",
    "    grid_w = np.arange(grid_size[2], dtype=np.float32)\n",
    "    grid = np.meshgrid(grid_w, grid_h, grid_d)  # here w, h, d goes first\n",
    "    grid = np.stack(grid, axis=0)\n",
    "\n",
    "    grid = grid.reshape([3, 1, grid_size[0], grid_size[1], grid_size[2]])\n",
    "    pos_embed = get_3d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
    "\n",
    "    return pos_embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "        nn.init.constant_(m.weight, 1.0)\n",
    "    elif isinstance(m, nn.Conv3d) or isinstance(m, nn.ConvTranspose3d):\n",
    "        w = m.weight.data\n",
    "        torch.nn.init.xavier_uniform_(w.view([w.shape[0], -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim: int, fn: nn.Module) -> None:\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x: torch.FloatTensor, **kwargs) -> torch.FloatTensor:\n",
    "        return self.fn(self.norm(x), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim: int, hidden_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Attention(nn.Module):\n",
    "#     def __init__(self, dim: int, heads: int = 8, dim_head: int = 64) -> None:\n",
    "#         super().__init__()\n",
    "#         inner_dim = dim_head *  heads\n",
    "#         project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "#         self.heads = heads\n",
    "#         self.scale = dim_head ** -0.5\n",
    "\n",
    "#         self.attend = nn.Softmax(dim = -1)\n",
    "#         self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "#         self.to_out = nn.Linear(inner_dim, dim) if project_out else nn.Identity()\n",
    "\n",
    "#     def forward(self, x: torch.FloatTensor) -> torch.FloatTensor:\n",
    "#         qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "#         q, k, v = map(lambda t: rearrange(t, 'b (d h w) (head dim) -> b head (d h w) dim', head = self.heads), qkv)\n",
    "\n",
    "#         attn = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "#         attn = self.attend(attn)\n",
    "\n",
    "#         out = torch.matmul(attn, v)\n",
    "#         out = rearrange(out, 'b head (d h w) dim -> b (d h w) (head dim)')\n",
    "\n",
    "#         return self.to_out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim: int, heads: int = 8, dim_head: int = 64) -> None:\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Linear(inner_dim, dim) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        attn = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "        attn = self.attend(attn)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "\n",
    "        return self.to_out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim: int, depth: int, heads: int, dim_head: int, mlp_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for idx in range(depth):\n",
    "            layer = nn.ModuleList([PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head)),\n",
    "                                   PreNorm(dim, FeedForward(dim, mlp_dim))])\n",
    "            self.layers.append(layer)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTEncoder3D(nn.Module):\n",
    "        # \"dim\": 240, \"depth\": 6, \"heads\": 8, \"mlp_dim\": 512, \"channels\": 1, \"dim_head\": 64\n",
    "    def __init__(self, volume_size: Union[Tuple[int, int, int], int], patch_size: Union[Tuple[int, int, int], int],\n",
    "                 dim: int, depth: int, heads: int, mlp_dim: int, channels: int = 1, dim_head: int = 64) -> None:\n",
    "        super().__init__()\n",
    "        volume_depth, volume_height, volume_width = volume_size if isinstance(volume_size, tuple) else (volume_size, volume_size, volume_size)\n",
    "        patch_depth, patch_height, patch_width = patch_size if isinstance(patch_size, tuple) else (patch_size, patch_size, patch_size)\n",
    "\n",
    "        assert volume_depth % patch_depth == 0 and volume_height % patch_height == 0 and volume_width % patch_width == 0, 'Volume dimensions must be divisible by the patch size.'\n",
    "        en_pos_embedding = get_3d_sincos_pos_embed(dim, (volume_depth // patch_depth, volume_height // patch_height, volume_width // patch_width))\n",
    "        self.num_patches = (volume_depth // patch_depth) * (volume_height // patch_height) * (volume_width // patch_width)\n",
    "        self.patch_dim = channels * patch_depth * patch_height * patch_width\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            nn.Conv3d(channels, dim, kernel_size=patch_size, stride=patch_size),\n",
    "            Rearrange('b c d h w -> b (d h w) c'),\n",
    "        )\n",
    "        self.en_pos_embedding = nn.Parameter(torch.from_numpy(en_pos_embedding).float().unsqueeze(0), requires_grad=False)\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim)\n",
    "\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, volume: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        x = self.to_patch_embedding(volume)\n",
    "        x = x + self.en_pos_embedding\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTDecoder3D(nn.Module):\n",
    "    def __init__(self, volume_size: Union[Tuple[int, int, int], int], patch_size: Union[Tuple[int, int, int], int],\n",
    "                 dim: int, depth: int, heads: int, mlp_dim: int, channels: int = 1, dim_head: int = 64) -> None:\n",
    "        super().__init__()\n",
    "        volume_depth, volume_height, volume_width = volume_size if isinstance(volume_size, tuple) else (volume_size, volume_size, volume_size)\n",
    "        patch_depth, patch_height, patch_width = patch_size if isinstance(patch_size, tuple) else (patch_size, patch_size, patch_size)\n",
    "\n",
    "        assert volume_depth % patch_depth == 0 and volume_height % patch_height == 0 and volume_width % patch_width == 0, 'Volume dimensions must be divisible by the patch size.'\n",
    "        de_pos_embedding = get_3d_sincos_pos_embed(dim, (volume_depth // patch_depth, volume_height // patch_height, volume_width // patch_width))\n",
    "\n",
    "        self.num_patches = (volume_depth // patch_depth) * (volume_height // patch_height) * (volume_width // patch_width)\n",
    "        self.patch_dim = channels * patch_depth * patch_height * patch_width\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim)\n",
    "        self.de_pos_embedding = nn.Parameter(torch.from_numpy(de_pos_embedding).float().unsqueeze(0), requires_grad=False)\n",
    "        self.to_voxel = nn.Sequential(\n",
    "            Rearrange('b (d h w) c -> b c d h w', d=volume_depth // patch_depth, h=volume_height // patch_height, w=volume_width // patch_width),\n",
    "            nn.ConvTranspose3d(dim, channels, kernel_size=patch_size, stride=patch_size)\n",
    "        )\n",
    "\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, token: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        x = token + self.de_pos_embedding\n",
    "        x = self.transformer(x)\n",
    "        x = self.to_voxel(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_last_layer(self) -> nn.Parameter:\n",
    "        return self.to_voxel[-1].weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseQuantizer(nn.Module):\n",
    "    def __init__(self, embed_dim: int, n_embed: int, straight_through: bool = True, use_norm: bool = True,\n",
    "                 use_residual: bool = False, num_quantizers: Optional[int] = None) -> None:\n",
    "        super().__init__()\n",
    "        self.straight_through = straight_through\n",
    "        self.norm = lambda x: F.normalize(x, dim=-1) if use_norm else x\n",
    "\n",
    "        self.use_residual = use_residual\n",
    "        self.num_quantizers = num_quantizers\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.n_embed = n_embed\n",
    "\n",
    "        self.embedding = nn.Embedding(self.n_embed, self.embed_dim)\n",
    "        self.embedding.weight.data.normal_()\n",
    "        \n",
    "    def quantize(self, z: torch.FloatTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.LongTensor]:\n",
    "        pass\n",
    "    \n",
    "    def forward(self, z: torch.FloatTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.LongTensor]:\n",
    "        if not self.use_residual:\n",
    "            z_q, loss, encoding_indices = self.quantize(z)\n",
    "        else:\n",
    "            z_q = torch.zeros_like(z)\n",
    "            residual = z.detach().clone()\n",
    "\n",
    "            losses = []\n",
    "            encoding_indices = []\n",
    "\n",
    "            for _ in range(self.num_quantizers):\n",
    "                z_qi, loss, indices = self.quantize(residual.clone())\n",
    "                residual.sub_(z_qi)\n",
    "                z_q.add_(z_qi)\n",
    "\n",
    "                encoding_indices.append(indices)\n",
    "                losses.append(loss)\n",
    "\n",
    "            losses, encoding_indices = map(partial(torch.stack, dim = -1), (losses, encoding_indices))\n",
    "            loss = losses.mean()\n",
    "\n",
    "        # preserve gradients with straight-through estimator\n",
    "        if self.straight_through:\n",
    "            z_q = z + (z_q - z).detach()\n",
    "\n",
    "        return z_q, loss, encoding_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(BaseQuantizer):\n",
    "    def __init__(self, embed_dim: int, n_embed: int, beta: float = 0.25, use_norm: bool = True,\n",
    "                 use_residual: bool = False, num_quantizers: Optional[int] = None, **kwargs) -> None:\n",
    "        super().__init__(embed_dim, n_embed, True,\n",
    "                         use_norm, use_residual, num_quantizers)\n",
    "        \n",
    "        self.beta = beta\n",
    "\n",
    "    def quantize(self, z: torch.FloatTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.LongTensor]:\n",
    "        z_reshaped_norm = self.norm(z.view(-1, self.embed_dim))\n",
    "        embedding_norm = self.norm(self.embedding.weight)\n",
    "        \n",
    "        d = torch.sum(z_reshaped_norm ** 2, dim=1, keepdim=True) + \\\n",
    "            torch.sum(embedding_norm ** 2, dim=1) - 2 * \\\n",
    "            torch.einsum('b d, n d -> b n', z_reshaped_norm, embedding_norm)\n",
    "\n",
    "        encoding_indices = torch.argmin(d, dim=1).unsqueeze(1)\n",
    "        encoding_indices = encoding_indices.view(*z.shape[:-1])\n",
    "        \n",
    "        z_q = self.embedding(encoding_indices).view(z.shape)\n",
    "        z_qnorm, z_norm = self.norm(z_q), self.norm(z)\n",
    "        \n",
    "        # compute loss for embedding\n",
    "        loss = self.beta * torch.mean((z_qnorm.detach() - z_norm)**2) +  \\\n",
    "               torch.mean((z_qnorm - z_norm.detach())**2)\n",
    "\n",
    "        return z_qnorm, loss, encoding_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GumbelQuantizer(BaseQuantizer):\n",
    "    def __init__(self, embed_dim: int, n_embed: int, temp_init: float = 1.0,\n",
    "                 use_norm: bool = True, use_residual: bool = False, num_quantizers: Optional[int] = None, **kwargs) -> None:\n",
    "        super().__init__(embed_dim, n_embed, False,\n",
    "                         use_norm, use_residual, num_quantizers)\n",
    "        \n",
    "        self.temperature = temp_init\n",
    "        \n",
    "    def quantize(self, z: torch.FloatTensor, temp: Optional[float] = None) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.LongTensor]:\n",
    "        # force hard = True when we are in eval mode, as we must quantize\n",
    "        hard = not self.training\n",
    "        temp = self.temperature if temp is None else temp\n",
    "        \n",
    "        z_reshaped_norm = self.norm(z.view(-1, self.embed_dim))\n",
    "        embedding_norm = self.norm(self.embedding.weight)\n",
    "\n",
    "        logits = - torch.sum(z_reshaped_norm ** 2, dim=1, keepdim=True) - \\\n",
    "                 torch.sum(embedding_norm ** 2, dim=1) + 2 * \\\n",
    "                 torch.einsum('b d, n d -> b n', z_reshaped_norm, embedding_norm)\n",
    "        logits =  logits.view(*z.shape[:-1], -1)\n",
    "        \n",
    "        soft_one_hot = F.gumbel_softmax(logits, tau=temp, dim=-1, hard=hard)\n",
    "        z_qnorm = torch.matmul(soft_one_hot, embedding_norm)\n",
    "        \n",
    "        # kl divergence to the prior loss\n",
    "        logits =  F.log_softmax(logits, dim=-1) # use log_softmax because it is more numerically stable\n",
    "        loss = torch.sum(logits.exp() * (logits+math.log(self.n_embed)), dim=-1).mean()\n",
    "               \n",
    "        # get encoding via argmax\n",
    "        encoding_indices = soft_one_hot.argmax(dim=-1)\n",
    "        \n",
    "        return z_qnorm, loss, encoding_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTVQ3D(pl.LightningModule):\n",
    "    def __init__(self, volume_key: str, volume_size: int, patch_size: int, encoder: OmegaConf, decoder: OmegaConf, quantizer: OmegaConf,\n",
    "                 path: Optional[str] = None, ignore_keys: List[str] = list(), scheduler: Optional[OmegaConf] = None) -> None:\n",
    "        # loss: OmegaConf, \n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.ignore_keys = ignore_keys \n",
    "        self.volume_key = volume_key\n",
    "        self.scheduler = scheduler \n",
    "        \n",
    "        # self.loss = initialize_from_config(loss)\n",
    "        # self.loss = VQVAELoss()\n",
    "        self.encoder = ViTEncoder3D(volume_size=volume_size, patch_size=patch_size, **encoder)\n",
    "        self.decoder = ViTDecoder3D(volume_size=volume_size, patch_size=patch_size, **decoder)\n",
    "        self.quantizer = VectorQuantizer(**quantizer)\n",
    "        # self.pre_quant = nn.Linear(encoder.dim, quantizer.embed_dim)\n",
    "        # self.post_quant = nn.Linear(quantizer.embed_dim, decoder.dim)\n",
    "        self.pre_quant = nn.Linear(encoder[\"dim\"], quantizer[\"embed_dim\"])\n",
    "        self.post_quant = nn.Linear(quantizer[\"embed_dim\"], decoder[\"dim\"])\n",
    "\n",
    "        if path is not None:\n",
    "            self.init_from_ckpt(path, ignore_keys)\n",
    "\n",
    "    def forward(self, x: torch.FloatTensor) -> torch.FloatTensor:    \n",
    "        quant, diff = self.encode(x)\n",
    "        dec = self.decode(quant)\n",
    "        \n",
    "        return dec, diff\n",
    "\n",
    "    def init_from_ckpt(self, path: str, ignore_keys: List[str] = list()):\n",
    "        sd = torch.load(path, map_location=\"cpu\")[\"state_dict\"]\n",
    "        keys = list(sd.keys())\n",
    "        for k in keys:\n",
    "            for ik in ignore_keys:\n",
    "                if k.startswith(ik):\n",
    "                    print(\"Deleting key {} from state_dict.\".format(k))\n",
    "                    del sd[k]\n",
    "        self.load_state_dict(sd, strict=False)\n",
    "        print(f\"Restored from {path}\")\n",
    "        \n",
    "    def encode(self, x: torch.FloatTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n",
    "        h = self.encoder(x)\n",
    "        h = self.pre_quant(h)\n",
    "        quant, emb_loss, _ = self.quantizer(h)\n",
    "        \n",
    "        return quant, emb_loss\n",
    "\n",
    "    def decode(self, quant: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        quant = self.post_quant(quant)\n",
    "        dec = self.decoder(quant)\n",
    "        \n",
    "        return dec\n",
    "\n",
    "    def encode_codes(self, x: torch.FloatTensor) -> torch.LongTensor:\n",
    "        h = self.encoder(x)\n",
    "        h = self.pre_quant(h)\n",
    "        _, _, codes = self.quantizer(h)\n",
    "        \n",
    "        return codes\n",
    "\n",
    "    def decode_codes(self, code: torch.LongTensor) -> torch.FloatTensor:\n",
    "        quant = self.quantizer.embedding(code)\n",
    "        quant = self.quantizer.norm(quant)\n",
    "        \n",
    "        if self.quantizer.use_residual:\n",
    "            quant = quant.sum(-2)  \n",
    "            \n",
    "        dec = self.decode(quant)\n",
    "        \n",
    "        return dec\n",
    "\n",
    "    def get_input(self, batch: Tuple[Any, Any], key: str = 'volume') -> Any:\n",
    "        x = batch[key]\n",
    "        if len(x.shape) == 4:\n",
    "            x = x[..., None]\n",
    "        if x.dtype == torch.double:\n",
    "            x = x.float()\n",
    "\n",
    "        return x.contiguous()\n",
    "\n",
    "    def training_step(self, batch: Tuple[Any, Any], batch_idx: int, optimizer_idx: int = 0) -> torch.FloatTensor:\n",
    "        x = self.get_input(batch, self.volume_key)\n",
    "        xrec, qloss = self(x)\n",
    "\n",
    "        if optimizer_idx == 0:\n",
    "            # autoencoder\n",
    "            aeloss, log_dict_ae = self.loss(qloss, x, xrec, optimizer_idx, self.global_step, batch_idx,\n",
    "                                            last_layer=self.decoder.get_last_layer(), split=\"train\")\n",
    "\n",
    "            self.log(\"train/total_loss\", aeloss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "            del log_dict_ae[\"train/total_loss\"]\n",
    "            \n",
    "            self.log_dict(log_dict_ae, prog_bar=False, logger=True, on_step=True, on_epoch=True)\n",
    "\n",
    "            return aeloss\n",
    "\n",
    "        if optimizer_idx == 1:\n",
    "            # discriminator\n",
    "            discloss, log_dict_disc = self.loss(qloss, x, xrec, optimizer_idx, self.global_step, batch_idx,\n",
    "                                                last_layer=self.decoder.get_last_layer(), split=\"train\")\n",
    "            \n",
    "            self.log(\"train/disc_loss\", discloss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "            del log_dict_disc[\"train/disc_loss\"]\n",
    "            \n",
    "            self.log_dict(log_dict_disc, prog_bar=False, logger=True, on_step=True, on_epoch=True)\n",
    "            \n",
    "            return discloss\n",
    "\n",
    "    def validation_step(self, batch: Tuple[Any, Any], batch_idx: int) -> Dict:\n",
    "        x = self.get_input(batch, self.volume_key)\n",
    "        xrec, qloss = self(x)\n",
    "        aeloss, log_dict_ae = self.loss(qloss, x, xrec, 0, self.global_step, batch_idx,\n",
    "                                        last_layer=self.decoder.get_last_layer(), split=\"val\")\n",
    "\n",
    "        rec_loss = log_dict_ae[\"val/rec_loss\"]\n",
    "\n",
    "        self.log(\"val/rec_loss\", rec_loss, prog_bar=True, logger=True, on_step=True, on_epoch=True, sync_dist=True)\n",
    "        self.log(\"val/total_loss\", aeloss, prog_bar=True, logger=True, on_step=True, on_epoch=True, sync_dist=True)\n",
    "        del log_dict_ae[\"val/rec_loss\"]\n",
    "        del log_dict_ae[\"val/total_loss\"]\n",
    "\n",
    "        self.log_dict(log_dict_ae, prog_bar=False, logger=True, on_step=True, on_epoch=True)\n",
    "\n",
    "        if hasattr(self.loss, 'discriminator'):\n",
    "            discloss, log_dict_disc = self.loss(qloss, x, xrec, 1, self.global_step, batch_idx,\n",
    "                                                last_layer=self.decoder.get_last_layer(), split=\"val\")\n",
    "            \n",
    "            self.log_dict(log_dict_disc, prog_bar=False, logger=True, on_step=True, on_epoch=True)\n",
    "        \n",
    "        return self.log_dict\n",
    "\n",
    "    def configure_optimizers(self) -> Tuple[List, List]:\n",
    "        lr = self.learning_rate\n",
    "        optim_groups = list(self.encoder.parameters()) + \\\n",
    "                       list(self.decoder.parameters()) + \\\n",
    "                       list(self.pre_quant.parameters()) + \\\n",
    "                       list(self.post_quant.parameters()) + \\\n",
    "                       list(self.quantizer.parameters())\n",
    "        \n",
    "        optimizers = [torch.optim.AdamW(optim_groups, lr=lr, betas=(0.9, 0.99), weight_decay=1e-4)]\n",
    "        schedulers = []\n",
    "        \n",
    "        if hasattr(self.loss, 'discriminator'):\n",
    "            optimizers.append(torch.optim.AdamW(self.loss.discriminator.parameters(), lr=lr, betas=(0.9, 0.99), weight_decay=1e-4))\n",
    "\n",
    "        if self.scheduler is not None:\n",
    "            self.scheduler.params.start = lr\n",
    "            scheduler = initialize_from_config(self.scheduler)\n",
    "            \n",
    "            schedulers = [\n",
    "                {\n",
    "                    'scheduler': lr_scheduler.LambdaLR(optimizer, lr_lambda=scheduler.schedule),\n",
    "                    'interval': 'step',\n",
    "                    'frequency': 1\n",
    "                } for optimizer in optimizers\n",
    "            ]\n",
    "   \n",
    "        return optimizers, schedulers\n",
    "        \n",
    "    def log_images(self, batch: Tuple[Any, Any], *args, **kwargs) -> Dict:\n",
    "        log = dict()\n",
    "        x = self.get_input(batch, self.volume_key).to(self.device)\n",
    "        quant, _ = self.encode(x)\n",
    "        \n",
    "        log[\"originals\"] = x\n",
    "        log[\"reconstructions\"] = self.decode(quant)\n",
    "        \n",
    "        return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ViTVQ3D(\n",
    "#     volume_key=\"volume\", volume_size=96, patch_size=8,\n",
    "#     encoder={\n",
    "#         \"dim\": 240, \"depth\": 6, \"heads\": 8, \"mlp_dim\": 512, \"channels\": 1, \"dim_head\": 64\n",
    "#     },\n",
    "#     decoder={\n",
    "#         \"dim\": 240, \"depth\": 6, \"heads\": 8, \"mlp_dim\": 512, \"channels\": 1, \"dim_head\": 64\n",
    "#     },\n",
    "#     quantizer={\n",
    "#         \"embed_dim\": 64, \"n_embed\": 512, \"beta\": 0.25, \"use_norm\": True, \"use_residual\": False\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTVQGumbel3D(ViTVQ3D):\n",
    "    def __init__(self, volume_key: str, volume_size: int, patch_size: int, encoder: OmegaConf, decoder: OmegaConf, quantizer: OmegaConf, loss: OmegaConf,\n",
    "                 path: Optional[str] = None, ignore_keys: List[str] = list(), temperature_scheduler: OmegaConf = None, scheduler: Optional[OmegaConf] = None) -> None:\n",
    "        super().__init__(volume_key, volume_size, patch_size, encoder, decoder, quantizer, loss, None, None, scheduler)\n",
    "\n",
    "        self.temperature_scheduler = initialize_from_config(temperature_scheduler) \\\n",
    "                                     if temperature_scheduler else None\n",
    "        self.quantizer = GumbelQuantizer(**quantizer)\n",
    "\n",
    "        if path is not None:\n",
    "            self.init_from_ckpt(path, ignore_keys)\n",
    "\n",
    "    def training_step(self, batch: Tuple[Any, Any], batch_idx: int, optimizer_idx: int = 0) -> torch.FloatTensor:\n",
    "        if self.temperature_scheduler:\n",
    "            self.quantizer.temperature = self.temperature_scheduler(self.global_step)\n",
    "\n",
    "        loss = super().training_step(batch, batch_idx, optimizer_idx)\n",
    "        \n",
    "        if optimizer_idx == 0:\n",
    "            self.log(\"temperature\", self.quantizer.temperature, prog_bar=False, logger=True, on_step=True, on_epoch=True)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a 64*64*64 tensor float32\n",
    "# dx, dy, dz = 96, 96, 96\n",
    "# x = torch.randn(1, 1, dx, dy, dz).float()\n",
    "# # forward\n",
    "# out, diff = model(x)\n",
    "# # print(out.shape, diff)\n",
    "# # recon loss is between x and out\n",
    "# # diff is the embedding loss\n",
    "# # show the recon loss in MSE loss\n",
    "# recon_loss = F.mse_loss(x, out)\n",
    "# print(\"Reconstruction loss is \", recon_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nibabel as nib\n",
    "\n",
    "# nii_path = \"s0001.nii.gz\"\n",
    "# nii_file = nib.load(nii_path)\n",
    "# nii_data = nii_file.get_fdata()\n",
    "# print(\"nii_data.shape is \", nii_data.shape)\n",
    "# # show max and min value\n",
    "# print(\"max value is \", nii_data.max())\n",
    "# print(\"min value is \", nii_data.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clip the value from -1024 to 2976\n",
    "# # and normalize the value to 0-1\n",
    "# nii_data_clip = np.clip(nii_data, -1024, 2976)\n",
    "# nii_data_norm = (nii_data_clip - (-1024)) / (2976 - (-1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cut the center\n",
    "# dx, dy, dz = (96, 96, 96)\n",
    "# nii_data_norm_cut = nii_data_norm[32:32+dx, 32:32+dy, 32:32+dz]\n",
    "# print(\"nii_data_norm_cut.shape is \", nii_data_norm_cut.shape)\n",
    "# # input the nii_data_norm_cut to the model\n",
    "# nii_data_norm_cut_tensor = torch.tensor(nii_data_norm_cut).float()\n",
    "# nii_data_norm_cut_tensor = nii_data_norm_cut_tensor.unsqueeze(0).unsqueeze(0)\n",
    "# print(\"nii_data_norm_cut_tensor.shape is \", nii_data_norm_cut_tensor.shape)\n",
    "# out, cb_loss = model(nii_data_norm_cut_tensor)\n",
    "# print(\"Recon loss is \", F.mse_loss(nii_data_norm_cut_tensor, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.blocks.convolutions import Convolution, ResidualUnit\n",
    "from typing import Optional, Sequence, Tuple, Union\n",
    "from monai.networks.layers.factories import Act, Norm\n",
    "\n",
    "# apply the channel wise norm for all feature maps\n",
    "# Normalize activations\n",
    "def normalize_activations(features):\n",
    "    normalized_features = []\n",
    "    for feature in features:\n",
    "        # Compute the norm along the channel dimension\n",
    "        norm = torch.norm(feature, p=2, dim=1, keepdim=True)\n",
    "        # Normalize the feature map\n",
    "        normalized_feature = feature / (norm + 1e-8)  # Add a small value to avoid division by zero\n",
    "        normalized_features.append(normalized_feature)\n",
    "    return normalized_features\n",
    "\n",
    "# Compute l2 distance for each pair of feature maps\n",
    "def l2_distance(features1, features2):\n",
    "    l2_distances = []\n",
    "    for f1, f2 in zip(features1, features2):\n",
    "        # Compute the l2 distance\n",
    "        l2_dist = torch.norm(f1 - f2, p=2, dim=1)  # Sum across channel dimension\n",
    "        l2_distances.append(l2_dist)\n",
    "    return l2_distances\n",
    "\n",
    "# Average the l2 distances across spatial dimensions\n",
    "def average_spatial(distances):\n",
    "    averaged_distances = []\n",
    "    for dist in distances:\n",
    "        # Average across spatial dimensions (dimensions 1, 2, 3)\n",
    "        avg_dist = torch.mean(dist, dim=[1, 2, 3])\n",
    "        averaged_distances.append(avg_dist)\n",
    "    return averaged_distances\n",
    "\n",
    "# Overall average across all layers\n",
    "def average_all_layers(distances):\n",
    "    total_distance = torch.stack(distances).mean()\n",
    "    return total_distance\n",
    "\n",
    "class UNet3D_encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        channels: Sequence[int],\n",
    "        strides: Sequence[int],\n",
    "        kernel_size: Union[Sequence[int], int] = 3,\n",
    "        up_kernel_size: Union[Sequence[int], int] = 3,\n",
    "        num_res_units: int = 0,\n",
    "        act: Union[Tuple, str] = Act.PRELU,\n",
    "        norm: Union[Tuple, str] = Norm.INSTANCE,\n",
    "        dropout: float = 0.0,\n",
    "        bias: bool = True,\n",
    "        adn_ordering: str = \"NDA\",\n",
    "        dimensions: Optional[int] = None,\n",
    "        pretrained_path = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if len(channels) < 2:\n",
    "            raise ValueError(\"the length of `channels` should be no less than 2.\")\n",
    "        delta = len(strides) - (len(channels) - 1)\n",
    "        if delta < 0:\n",
    "            raise ValueError(\"the length of `strides` should equal to `len(channels) - 1`.\")\n",
    "        if delta > 0:\n",
    "            warnings.warn(f\"`len(strides) > len(channels) - 1`, the last {delta} values of strides will not be used.\")\n",
    "        if dimensions is not None:\n",
    "            spatial_dims = dimensions\n",
    "        if isinstance(kernel_size, Sequence):\n",
    "            if len(kernel_size) != spatial_dims:\n",
    "                raise ValueError(\"the length of `kernel_size` should equal to `dimensions`.\")\n",
    "        if isinstance(up_kernel_size, Sequence):\n",
    "            if len(up_kernel_size) != spatial_dims:\n",
    "                raise ValueError(\"the length of `up_kernel_size` should equal to `dimensions`.\")\n",
    "\n",
    "        self.dimensions = spatial_dims\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.channels = channels\n",
    "        self.strides = strides\n",
    "        self.kernel_size = kernel_size\n",
    "        self.up_kernel_size = up_kernel_size\n",
    "        self.num_res_units = num_res_units\n",
    "        self.act = act\n",
    "        self.norm = norm\n",
    "        self.dropout = dropout\n",
    "        self.bias = bias\n",
    "        self.adn_ordering = adn_ordering\n",
    "        self.pretrained_path = pretrained_path\n",
    "\n",
    "\n",
    "        # UNet( \n",
    "        # spatial_dims=unet_dict[\"spatial_dims\"],\n",
    "        # in_channels=unet_dict[\"in_channels\"],\n",
    "        # out_channels=unet_dict[\"out_channels\"],\n",
    "        # channels=unet_dict[\"channels\"],\n",
    "        # strides=unet_dict[\"strides\"],\n",
    "        # num_res_units=unet_dict[\"num_res_units\"],\n",
    "        # act=unet_dict[\"act\"],\n",
    "        # norm=unet_dict[\"normunet\"],\n",
    "        # dropout=unet_dict[\"dropout\"],\n",
    "        # bias=unet_dict[\"bias\"],\n",
    "        # )\n",
    "\n",
    "        # input - down1 ------------- up1 -- output\n",
    "        #         |                   |\n",
    "        #         down2 ------------- up2\n",
    "        #         |                   |\n",
    "        #         down3 ------------- up3\n",
    "        #         |                   |\n",
    "        #         down4 -- bottom --  up4\n",
    "        # 1 -> (32, 64, 128, 256) -> 1\n",
    "\n",
    "        self.down1 = ResidualUnit(3, self.in_channels, self.channels[0], self.strides[0],\n",
    "                kernel_size=self.kernel_size, subunits=self.num_res_units,\n",
    "                act=self.act, norm=self.norm, dropout=self.dropout,\n",
    "                bias=self.bias, adn_ordering=self.adn_ordering)\n",
    "        self.down2 = ResidualUnit(3, self.channels[0], self.channels[1], self.strides[1],\n",
    "                kernel_size=self.kernel_size, subunits=self.num_res_units,\n",
    "                act=self.act, norm=self.norm, dropout=self.dropout,\n",
    "                bias=self.bias, adn_ordering=self.adn_ordering)\n",
    "        self.down3 = ResidualUnit(3, self.channels[1], self.channels[2], self.strides[2],\n",
    "                kernel_size=self.kernel_size, subunits=self.num_res_units,\n",
    "                act=self.act, norm=self.norm, dropout=self.dropout,\n",
    "                bias=self.bias, adn_ordering=self.adn_ordering)\n",
    "        self.bottom = ResidualUnit(3, self.channels[2], self.channels[3], 1,\n",
    "                kernel_size=self.kernel_size, subunits=self.num_res_units,\n",
    "                act=self.act, norm=self.norm, dropout=self.dropout,\n",
    "                bias=self.bias, adn_ordering=self.adn_ordering)\n",
    "\n",
    "        self.load_weights(self.pretrained_path)\n",
    "        self.set_all_parameters_ignore_grad()\n",
    "    \n",
    "    def load_weights(self, path: str):\n",
    "        # the path is to the whole model, where we only need the encoder part\n",
    "        # iterate the current model weight names and load the weights from the pre-trained model\n",
    "        pretrain_dict = torch.load(path)\n",
    "        current_dict = self.state_dict()\n",
    "        # 1. filter out unnecessary keys\n",
    "        pretrain_dict = {k: v for k, v in pretrain_dict.items() if k in current_dict}\n",
    "        # 2. overwrite entries in the existing state dict\n",
    "        current_dict.update(pretrain_dict)\n",
    "        # 3. load the new state dict\n",
    "        self.load_state_dict(current_dict)\n",
    "\n",
    "    def set_all_parameters_ignore_grad(self):\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "    # def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    #     x1 = self.down1(x)\n",
    "    #     x2 = self.down2(x1)\n",
    "    #     x3 = self.down3(x2)\n",
    "    #     x4 = self.bottom(x3)\n",
    "    #     return x1, x2, x3, x4\n",
    "\n",
    "    def forward(self, y: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
    "        y1 = self.down1(y)\n",
    "        y2 = self.down2(y1)\n",
    "        y3 = self.down3(y2)\n",
    "        y4 = self.bottom(y3)\n",
    "\n",
    "        z1 = self.down1(z)\n",
    "        z2 = self.down2(z1)\n",
    "        z3 = self.down3(z2)\n",
    "        z4 = self.bottom(z3)\n",
    "\n",
    "        y_features = [y1, y2, y3, y4]\n",
    "        z_features = [z1, z2, z3, z4]\n",
    "\n",
    "        y_fea_norm = normalize_activations(y_features)\n",
    "        z_fea_norm = normalize_activations(z_features)\n",
    "\n",
    "        l2_dist = l2_distance(y_fea_norm, z_fea_norm)\n",
    "        avg_dist = average_spatial(l2_dist)\n",
    "        total_dist = average_all_layers(avg_dist)\n",
    "\n",
    "        return total_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from monai.networks.nets.unet import UNet as UNet\n",
    "\n",
    "# model = torch.load(\"model_best_181.pth\")\n",
    "# # save the state_dict\n",
    "# torch.save(model.state_dict(), \"model_best_181_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # here we set the encoder model parameters\n",
    "\n",
    "# preceptual_loss = dict()\n",
    "# preceptual_loss[\"spatial_dims\"] = 3\n",
    "# preceptual_loss[\"in_channels\"] = 1\n",
    "# preceptual_loss[\"out_channels\"] = 1\n",
    "# preceptual_loss[\"channels\"] = [32, 64, 128, 256]\n",
    "# preceptual_loss[\"strides\"] = [2, 2, 2]\n",
    "# preceptual_loss[\"num_res_units\"] = 4\n",
    "# preceptual_loss[\"pretrained_path\"] = \"model_best_181_state_dict.pth\"\n",
    "\n",
    "# preceptual_model = UNet3D_encoder(**preceptual_loss)\n",
    "# print(\"input size is \", nii_data_norm_cut_tensor.size(), \"output size is \", out.size())\n",
    "# total_dist = preceptual_model(nii_data_norm_cut_tensor, out)\n",
    "# print(\"total_dist is \", total_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconL2_loss = F.mse_loss(nii_data_norm_cut_tensor, out)\n",
    "# reconL1_loss = F.l1_loss(nii_data_norm_cut_tensor, out)\n",
    "# perceptual_loss = total_dist\n",
    "# codebook_loss = cb_loss\n",
    "# print(\"Recon L2 loss is \", reconL2_loss)\n",
    "# print(\"Recon L1 loss is \", reconL1_loss)\n",
    "# print(\"Perceptual loss is \", perceptual_loss)\n",
    "# print(\"Codebook loss is \", codebook_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # show the plot for max and min for both xn_y and xn_z for x1 to x4\n",
    "\n",
    "# def describe_data(name, data):\n",
    "#     # print(name, \"MAX: \", data.max(), \"MIN: \", data.min(), \"MIN: \", data.mean(), \"STD: \", data.std())\n",
    "#     print(f\"{name} MAX: {data.max():4f} MIN: {data.min():4f} MEAN: {data.mean():4f} STD: {data.std():4f}\")\n",
    "    \n",
    "# def check_max_and_min(features, names):\n",
    "#     for idx, feature in enumerate(features):\n",
    "#         feature_numpy = feature.detach().numpy()\n",
    "#         feature_numpy_channel_max = feature_numpy.max(axis=(0, 2, 3, 4))\n",
    "#         feature_numpy_channel_min = feature_numpy.min(axis=(0, 2, 3, 4))\n",
    "#         feature_numpy_channel_mean = feature_numpy.mean(axis=(0, 2, 3, 4))\n",
    "#         feature_numpy_channel_std = feature_numpy.std(axis=(0, 2, 3, 4))\n",
    "#         print(\"-\"*20)\n",
    "#         describe_data(names[idx], feature_numpy_channel_max)\n",
    "#         describe_data(names[idx], feature_numpy_channel_min)\n",
    "#         describe_data(names[idx], feature_numpy_channel_mean)\n",
    "#         describe_data(names[idx], feature_numpy_channel_std)\n",
    "\n",
    "# check_max_and_min([x1_y, x2_y, x3_y, x4_y], [\"x1_y\", \"x2_y\", \"x3_y\", \"x4_y\"])\n",
    "# check_max_and_min([x1_z, x2_z, x3_z, x4_z], [\"x1_z\", \"x2_z\", \"x3_z\", \"x4_z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # apply the channel wise norm for all feature maps\n",
    "# # Normalize activations\n",
    "# def normalize_activations(features):\n",
    "#     normalized_features = []\n",
    "#     for feature in features:\n",
    "#         # Compute the norm along the channel dimension\n",
    "#         norm = torch.norm(feature, p=2, dim=1, keepdim=True)\n",
    "#         # Normalize the feature map\n",
    "#         normalized_feature = feature / (norm + 1e-8)  # Add a small value to avoid division by zero\n",
    "#         normalized_features.append(normalized_feature)\n",
    "#     return normalized_features\n",
    "\n",
    "# # Compute l2 distance for each pair of feature maps\n",
    "# def l2_distance(features1, features2):\n",
    "#     l2_distances = []\n",
    "#     for f1, f2 in zip(features1, features2):\n",
    "#         # Compute the l2 distance\n",
    "#         l2_dist = torch.norm(f1 - f2, p=2, dim=1)  # Sum across channel dimension\n",
    "#         l2_distances.append(l2_dist)\n",
    "#     return l2_distances\n",
    "\n",
    "# # Average the l2 distances across spatial dimensions\n",
    "# def average_spatial(distances):\n",
    "#     averaged_distances = []\n",
    "#     for dist in distances:\n",
    "#         # Average across spatial dimensions (dimensions 1, 2, 3)\n",
    "#         avg_dist = torch.mean(dist, dim=[1, 2, 3])\n",
    "#         averaged_distances.append(avg_dist)\n",
    "#     return averaged_distances\n",
    "\n",
    "# # Overall average across all layers\n",
    "# def average_all_layers(distances):\n",
    "#     total_distance = torch.stack(distances).mean()\n",
    "#     return total_distance\n",
    "\n",
    "# y_features = normalize_activations([x1_y, x2_y, x3_y, x4_y])\n",
    "# z_features = normalize_activations([x1_z, x2_z, x3_z, x4_z])\n",
    "\n",
    "# check_max_and_min(y_features, [\"x1_y_norm\", \"x2_y_norm\", \"x3_y_norm\", \"x4_y_norm\"])\n",
    "# check_max_and_min(z_features, [\"x1_z_norm\", \"x2_z_norm\", \"x3_z_norm\", \"x4_z_norm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate l2 distances\n",
    "# l2_distances = l2_distance(y_features, z_features)\n",
    "\n",
    "# # Average across spatial dimensions\n",
    "# averaged_spatial_distances = average_spatial(l2_distances)\n",
    "\n",
    "# # Final perceptual loss\n",
    "# final_distance = average_all_layers(averaged_spatial_distances)\n",
    "\n",
    "# print(f'Final Distance: {final_distance.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import (\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandSpatialCropd,\n",
    "    # random flip and rotate\n",
    "    RandFlipd,\n",
    "    RandRotated,\n",
    ")\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\"],\n",
    "            pixdim=(pix_dim, pix_dim, pix_dim),\n",
    "            mode=(\"bilinear\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-1024,\n",
    "            a_max=2976,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "        # random crop to the target size\n",
    "        RandSpatialCropd(keys=[\"image\"], roi_size=(volume_size, volume_size, volume_size), random_center=True, random_size=False),\n",
    "        # add random flip and rotate\n",
    "        RandFlipd(keys=[\"image\"], prob=0.5, spatial_axis=0),\n",
    "        RandFlipd(keys=[\"image\"], prob=0.5, spatial_axis=1),\n",
    "        RandFlipd(keys=[\"image\"], prob=0.5, spatial_axis=2),\n",
    "        RandRotated(keys=[\"image\"], prob=0.5, range_x=15, range_y=15, range_z=15),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\"],\n",
    "            pixdim=(pix_dim, pix_dim, pix_dim),\n",
    "            mode=(\"bilinear\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=-1024, a_max=2976, b_min=0.0, b_max=1.0, clip=True),\n",
    "        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "        RandSpatialCropd(keys=[\"image\"], roi_size=(volume_size, volume_size, volume_size), random_center=True, random_size=False),\n",
    "        RandFlipd(keys=[\"image\"], prob=0.5, spatial_axis=0),\n",
    "        RandFlipd(keys=[\"image\"], prob=0.5, spatial_axis=1),\n",
    "        RandFlipd(keys=[\"image\"], prob=0.5, spatial_axis=2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Tue Jun 25 22:33:19 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:17:00.0 Off |                  Off |\n",
      "| 30%   34C    P8    18W / 230W |      1MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A5000    Off  | 00000000:65:00.0 Off |                  Off |\n",
      "| 30%   29C    P8    17W / 230W |      1MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# check CUDA device\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(device)\n",
    "# show Memory for device\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # divide the training, validation and validation set\n",
    "# import glob\n",
    "\n",
    "# ct_file_list = sorted(glob.glob(\"tsv1_ct/*.nii.gz\"))\n",
    "# print(\"total ct files are \", len(ct_file_list))\n",
    "\n",
    "# # divide the training, validation and test set by 5:3:2\n",
    "\n",
    "# import random\n",
    "# import json\n",
    "\n",
    "# random.shuffle(ct_file_list)\n",
    "# # divide the whole dataset into 10 pieces, and save them into chunk_0 to chunk_9\n",
    "\n",
    "# chunk_size = len(ct_file_list) // 10\n",
    "\n",
    "# # save them into data_chunks.json\n",
    "# # data_chunks.json is a dictionary, key is the chunk number, value is the list of file names\n",
    "# data_chunk = dict()\n",
    "# for i in range(10):\n",
    "#     start = i * chunk_size\n",
    "#     end = (i + 1) * chunk_size\n",
    "#     if i == 9:\n",
    "#         end = len(ct_file_list)\n",
    "#     # data_chunk[f\"chunk_{i}\"] = ct_file_list[start:end]\n",
    "#     # in each item, it will be {\"image\": \"tsv1_ct/xxx.nii.gz\"}\n",
    "#     data_chunk[f\"chunk_{i}\"] = [{\"image\": ct_file} for ct_file in ct_file_list[start:end]]\n",
    "\n",
    "# with open(\"data_chunks.json\", \"w\") as f:\n",
    "#     json.dump(data_chunk, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files are  575\n",
      "Val files are  345\n",
      "Test files are  233\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# load data_chunks.json and specif chunk_0 to chunk_4 for training, chunk_5 to chunk_7 for validation, chunk_8 and chunk_9 for testing\n",
    "with open(\"data_chunks.json\", \"r\") as f:\n",
    "    data_chunk = json.load(f)\n",
    "\n",
    "train_files = []\n",
    "val_files = []\n",
    "test_files = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_files.extend(data_chunk[f\"chunk_{i}\"])\n",
    "for i in range(5, 8):\n",
    "    val_files.extend(data_chunk[f\"chunk_{i}\"])\n",
    "for i in range(8, 10):\n",
    "    test_files.extend(data_chunk[f\"chunk_{i}\"])\n",
    "\n",
    "num_train_files = len(train_files)\n",
    "num_val_files = len(val_files)\n",
    "num_test_files = len(test_files)\n",
    "\n",
    "print(\"Train files are \", len(train_files))\n",
    "print(\"Val files are \", len(val_files))\n",
    "print(\"Test files are \", len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, default_collate\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class RobustCacheDataset(CacheDataset):\n",
    "    def __init__(self, data, transform=None, cache_num=0, cache_rate=1.0, num_workers=0):\n",
    "        super().__init__(data, transform=transform, cache_num=cache_num, cache_rate=cache_rate, num_workers=num_workers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            # Fetch the cached data\n",
    "            data = super().__getitem__(idx)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data at index {idx}: {e}\")\n",
    "            # Handle the error appropriately, for example, return None or a default value\n",
    "            return None\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(worker_id)\n",
    "    random.seed(worker_id)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    return default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:   0%|                                                                         | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 115/115 [00:36<00:00,  3.15it/s]\n",
      "Loading dataset: 100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 34/34 [00:12<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds = RobustCacheDataset(\n",
    "    data=train_files,\n",
    "    transform=train_transforms,\n",
    "    cache_num=num_train_files,\n",
    "    cache_rate=0.2, # 600 * 0.1 = 60\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "val_ds = RobustCacheDataset(\n",
    "    data=val_files,\n",
    "    transform=val_transforms, \n",
    "    cache_num=num_val_files,\n",
    "    cache_rate=0.1, # 360 * 0.05 = 18\n",
    "    num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4, worker_init_fn=worker_init_fn, collate_fn=collate_fn, timeout=60)\n",
    "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=4, worker_init_fn=worker_init_fn, collate_fn=collate_fn, timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-25 22:34:09,711 - Created a temporary directory at /tmp/tmpienn0c3f\n",
      "2024-06-25 22:34:09,712 - Writing /tmp/tmpienn0c3f/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "model = ViTVQ3D(\n",
    "    volume_key=\"volume\", volume_size=volume_size, patch_size=8,\n",
    "    encoder={\n",
    "        \"dim\": 360, \"depth\": 6, \"heads\": 16, \"mlp_dim\": 1024, \"channels\": 1, \"dim_head\": 128\n",
    "    },\n",
    "    decoder={\n",
    "        \"dim\": 360, \"depth\": 6, \"heads\": 16, \"mlp_dim\": 1024, \"channels\": 1, \"dim_head\": 128\n",
    "    },\n",
    "    quantizer={\n",
    "        \"embed_dim\": 128, \"n_embed\": 1024, \"beta\": 0.25, \"use_norm\": True, \"use_residual\": False\n",
    "    }\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-4\n",
    "# use AdamW optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we set the encoder model parameters\n",
    "\n",
    "preceptual_loss = dict()\n",
    "preceptual_loss[\"spatial_dims\"] = 3\n",
    "preceptual_loss[\"in_channels\"] = 1\n",
    "preceptual_loss[\"out_channels\"] = 1\n",
    "preceptual_loss[\"channels\"] = [32, 64, 128, 256]\n",
    "preceptual_loss[\"strides\"] = [2, 2, 2]\n",
    "preceptual_loss[\"num_res_units\"] = 4\n",
    "preceptual_loss[\"pretrained_path\"] = \"model_best_181_state_dict.pth\"\n",
    "\n",
    "preceptual_model = UNet3D_encoder(**preceptual_loss).to(device)\n",
    "# total_dist = preceptual_model(nii_data_norm_cut_tensor, out)\n",
    "# print(\"total_dist is \", total_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a logger for the training\n",
    "# every time called logger.log(), it will save the log into the file\n",
    "import time\n",
    "\n",
    "class simple_logger():\n",
    "    def __init__(self, log_file_path):\n",
    "        self.log_file_path = log_file_path\n",
    "        self.log_dict = dict()\n",
    "    \n",
    "    def log(self, global_epoch, key, msg):\n",
    "        if key not in self.log_dict.keys():\n",
    "            self.log_dict[key] = dict()\n",
    "        current_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "        self.log_dict[key] = {\n",
    "            \"time\": current_time,\n",
    "            \"global_epoch\": global_epoch,\n",
    "            \"msg\": msg\n",
    "        }\n",
    "        log_str = f\"{current_time} Global epoch: {global_epoch}, {key}, {msg}\\n\"\n",
    "        with open(self.log_file_path, \"a\") as f:\n",
    "            f.write(log_str)\n",
    "        print(log_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "current_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "log_file_path = f\"train_log_{current_time}.json\"\n",
    "logger = simple_logger(log_file_path)\n",
    "\n",
    "num_epoch = 1000\n",
    "loss_weights = {\n",
    "    \"reconL2\": 1.0, \n",
    "    \"reconL1\": 0.1, \n",
    "    \"perceptual\": 0.05, \n",
    "    \"codebook\": 0.1}\n",
    "val_per_epoch = 20\n",
    "num_train_batch = len(train_loader)\n",
    "num_val_batch = len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<0> [0/18] Total loss: 0.9360347986221313\n",
      "<0> [1/18] Total loss: 1.0179909467697144\n",
      "<0> [2/18] Total loss: 0.4376298785209656\n",
      "<0> [3/18] Total loss: 0.2809537351131439\n",
      "<0> [4/18] Total loss: 0.20731933414936066\n",
      "<0> [5/18] Total loss: 0.1707051396369934\n",
      "<0> [6/18] Total loss: 0.1455327719449997\n",
      "<0> [7/18] Total loss: 0.12855277955532074\n",
      "<0> [8/18] Total loss: 0.11861488223075867\n",
      "<0> [9/18] Total loss: 0.11713769286870956\n",
      "<0> [10/18] Total loss: 0.1187293529510498\n",
      "<0> [11/18] Total loss: 0.11842599511146545\n",
      "<0> [12/18] Total loss: 0.11711177974939346\n",
      "<0> [13/18] Total loss: 0.12094827741384506\n",
      "<0> [14/18] Total loss: 0.11760570108890533\n",
      "<0> [15/18] Total loss: 0.11644783616065979\n",
      "<0> [16/18] Total loss: 0.11109942197799683\n",
      "<0> [17/18] Total loss: 0.10906561464071274\n",
      "2024-06-25-22-35-58 Global epoch: 0, train_reconL2_mean, 0.16187313116259044\n",
      "\n",
      "2024-06-25-22-35-58 Global epoch: 0, train_reconL2_std, 0.25110155183205246\n",
      "\n",
      "2024-06-25-22-35-58 Global epoch: 0, train_reconL1_mean, 0.26168151282601887\n",
      "\n",
      "2024-06-25-22-35-58 Global epoch: 0, train_reconL1_std, 0.1817330699768515\n",
      "\n",
      "2024-06-25-22-35-58 Global epoch: 0, train_perceptual_mean, 1.200116667482588\n",
      "\n",
      "2024-06-25-22-35-58 Global epoch: 0, train_perceptual_std, 0.014805526196512207\n",
      "\n",
      "2024-06-25-22-35-58 Global epoch: 0, train_codebook_mean, 0.013920991578035884\n",
      "\n",
      "2024-06-25-22-35-58 Global epoch: 0, train_codebook_std, 0.00023416285558131781\n",
      "\n",
      "2024-06-25-22-35-58 Global epoch: 0, train_total_mean, 0.24943921880589592\n",
      "\n",
      "2024-06-25-22-35-58 Global epoch: 0, train_total_std, 0.2696371531926405\n",
      "\n",
      "<0> [0/22] Total loss: 0.10302694886922836\n",
      "<0> [1/22] Total loss: 0.10664363205432892\n",
      "<0> [2/22] Total loss: 0.10785836726427078\n",
      "<0> [3/22] Total loss: 0.10554589331150055\n",
      "<0> [4/22] Total loss: 0.10366102308034897\n",
      "<0> [5/22] Total loss: 0.10694540292024612\n",
      "<0> [6/22] Total loss: 0.10604176670312881\n",
      "<0> [7/22] Total loss: 0.10313509404659271\n",
      "<0> [8/22] Total loss: 0.1060028225183487\n",
      "<0> [9/22] Total loss: 0.10776301473379135\n",
      "<0> [10/22] Total loss: 0.10347992926836014\n",
      "<0> [11/22] Total loss: 0.10617873072624207\n",
      "<0> [12/22] Total loss: 0.10168257355690002\n",
      "<0> [13/22] Total loss: 0.10524536669254303\n",
      "<0> [14/22] Total loss: 0.10281411558389664\n",
      "<0> [15/22] Total loss: 0.10648368299007416\n",
      "<0> [16/22] Total loss: 0.10255313664674759\n",
      "<0> [17/22] Total loss: 0.10587623715400696\n",
      "<0> [18/22] Total loss: 0.1096043810248375\n",
      "<0> [19/22] Total loss: 0.10130994766950607\n",
      "<0> [20/22] Total loss: 0.10741543769836426\n",
      "<0> [21/22] Total loss: 0.11206813901662827\n",
      "2024-06-25-22-37-04 Global epoch: 0, val_reconL2_mean, 0.031045330519025974\n",
      "\n",
      "2024-06-25-22-37-04 Global epoch: 0, val_reconL2_std, 0.002004846817958292\n",
      "\n",
      "2024-06-25-22-37-04 Global epoch: 0, val_reconL1_mean, 0.1418946019627831\n",
      "\n",
      "2024-06-25-22-37-04 Global epoch: 0, val_reconL1_std, 0.005333351080933607\n",
      "\n",
      "2024-06-25-22-37-04 Global epoch: 0, val_perceptual_mean, 1.1776357997547497\n",
      "\n",
      "2024-06-25-22-37-04 Global epoch: 0, val_perceptual_std, 0.0018285423447272175\n",
      "\n",
      "2024-06-25-22-37-04 Global epoch: 0, val_codebook_mean, 0.013986754231154919\n",
      "\n",
      "2024-06-25-22-37-04 Global epoch: 0, val_codebook_std, 7.774402733096037e-07\n",
      "\n",
      "2024-06-25-22-37-04 Global epoch: 0, val_total_mean, 0.105515256524086\n",
      "\n",
      "2024-06-25-22-37-04 Global epoch: 0, val_total_std, 0.0025859065941097274\n",
      "\n",
      "<1> [0/18] Total loss: 0.10488972812891006\n",
      "<1> [1/18] Total loss: 0.10101927071809769\n",
      "<1> [2/18] Total loss: 0.09811288118362427\n",
      "<1> [3/18] Total loss: 0.0973873883485794\n",
      "<1> [4/18] Total loss: 0.0934496521949768\n",
      "<1> [5/18] Total loss: 0.09147052466869354\n",
      "<1> [6/18] Total loss: 0.09061599522829056\n",
      "<1> [7/18] Total loss: 0.09455610811710358\n",
      "<1> [8/18] Total loss: 0.09015364199876785\n",
      "<1> [9/18] Total loss: 0.09642044454813004\n",
      "<1> [10/18] Total loss: 0.09419142454862595\n",
      "<1> [11/18] Total loss: 0.09123997390270233\n",
      "<1> [12/18] Total loss: 0.09189379215240479\n",
      "<1> [13/18] Total loss: 0.09351303428411484\n",
      "<1> [14/18] Total loss: 0.08943097293376923\n",
      "<1> [15/18] Total loss: 0.09235119819641113\n",
      "<1> [16/18] Total loss: 0.08934513479471207\n",
      "<1> [17/18] Total loss: 0.08740496635437012\n",
      "2024-06-25-22-38-54 Global epoch: 1, train_reconL2_mean, 0.021929777330822416\n",
      "\n",
      "2024-06-25-22-38-54 Global epoch: 1, train_reconL2_std, 0.0032181293568348496\n",
      "\n",
      "2024-06-25-22-38-54 Global epoch: 1, train_reconL1_mean, 0.12403280039628346\n",
      "\n",
      "2024-06-25-22-38-54 Global epoch: 1, train_reconL1_std, 0.00679373696210332\n",
      "\n",
      "2024-06-25-22-38-54 Global epoch: 1, train_perceptual_mean, 1.160551647345225\n",
      "\n",
      "2024-06-25-22-38-54 Global epoch: 1, train_perceptual_std, 0.011309573814964726\n",
      "\n",
      "2024-06-25-22-38-54 Global epoch: 1, train_codebook_mean, 0.013863670070552163\n",
      "\n",
      "2024-06-25-22-38-54 Global epoch: 1, train_codebook_std, 9.952377356474851e-05\n",
      "\n",
      "2024-06-25-22-38-54 Global epoch: 1, train_total_mean, 0.0937470073501269\n",
      "\n",
      "2024-06-25-22-38-54 Global epoch: 1, train_total_std, 0.004315950777295127\n",
      "\n",
      "<2> [0/18] Total loss: 0.08822482079267502\n",
      "<2> [1/18] Total loss: 0.08936063945293427\n",
      "<2> [2/18] Total loss: 0.08779297024011612\n",
      "<2> [3/18] Total loss: 0.08762325346469879\n",
      "<2> [4/18] Total loss: 0.08801423013210297\n",
      "<2> [5/18] Total loss: 0.08807656168937683\n",
      "<2> [6/18] Total loss: 0.08251424878835678\n",
      "<2> [7/18] Total loss: 0.08365921676158905\n",
      "<2> [8/18] Total loss: 0.09023495018482208\n",
      "<2> [9/18] Total loss: 0.08777344226837158\n",
      "<2> [10/18] Total loss: 0.08447977155447006\n",
      "<2> [11/18] Total loss: 0.08523327857255936\n",
      "<2> [12/18] Total loss: 0.08401356637477875\n",
      "<2> [13/18] Total loss: 0.0818253681063652\n",
      "<2> [14/18] Total loss: 0.08638820052146912\n",
      "<2> [15/18] Total loss: 0.08304426074028015\n",
      "<2> [16/18] Total loss: 0.08599401265382767\n",
      "<2> [17/18] Total loss: 0.08526486158370972\n",
      "2024-06-25-22-40-34 Global epoch: 2, train_reconL2_mean, 0.017250737899707422\n",
      "\n",
      "2024-06-25-22-40-34 Global epoch: 2, train_reconL2_std, 0.0015972685250093019\n",
      "\n",
      "2024-06-25-22-40-34 Global epoch: 2, train_reconL1_mean, 0.10989200199643771\n",
      "\n",
      "2024-06-25-22-40-34 Global epoch: 2, train_reconL1_std, 0.00546559034120874\n",
      "\n",
      "2024-06-25-22-40-34 Global epoch: 2, train_perceptual_mean, 1.130128436618381\n",
      "\n",
      "2024-06-25-22-40-34 Global epoch: 2, train_perceptual_std, 0.0068704766018728375\n",
      "\n",
      "2024-06-25-22-40-34 Global epoch: 2, train_codebook_mean, 0.013379521098815732\n",
      "\n",
      "2024-06-25-22-40-34 Global epoch: 2, train_codebook_std, 0.0001709417021403305\n",
      "\n",
      "2024-06-25-22-40-34 Global epoch: 2, train_total_mean, 0.08608431410458353\n",
      "\n",
      "2024-06-25-22-40-34 Global epoch: 2, train_total_std, 0.002389145640899101\n",
      "\n",
      "<3> [0/18] Total loss: 0.08747575432062149\n",
      "<3> [1/18] Total loss: 0.08681346476078033\n",
      "<3> [2/18] Total loss: 0.08556464314460754\n",
      "<3> [3/18] Total loss: 0.0864158421754837\n",
      "<3> [4/18] Total loss: 0.08615698665380478\n",
      "<3> [5/18] Total loss: 0.08601353317499161\n",
      "<3> [6/18] Total loss: 0.08839024603366852\n",
      "<3> [7/18] Total loss: 0.08408039063215256\n",
      "<3> [8/18] Total loss: 0.08558923751115799\n",
      "<3> [9/18] Total loss: 0.08632099628448486\n",
      "<3> [10/18] Total loss: 0.08687155693769455\n",
      "<3> [11/18] Total loss: 0.08545872569084167\n",
      "<3> [12/18] Total loss: 0.08652404695749283\n",
      "<3> [13/18] Total loss: 0.08475945144891739\n",
      "<3> [14/18] Total loss: 0.08557958155870438\n",
      "<3> [15/18] Total loss: 0.08631543070077896\n",
      "<3> [16/18] Total loss: 0.08634592592716217\n",
      "<3> [17/18] Total loss: 0.08724724501371384\n",
      "2024-06-25-22-42-17 Global epoch: 3, train_reconL2_mean, 0.017110897849003475\n",
      "\n",
      "2024-06-25-22-42-17 Global epoch: 3, train_reconL2_std, 0.0006669336485983921\n",
      "\n",
      "2024-06-25-22-42-17 Global epoch: 3, train_reconL1_mean, 0.11376326158642769\n",
      "\n",
      "2024-06-25-22-42-17 Global epoch: 3, train_reconL1_std, 0.0022255447006066698\n",
      "\n",
      "2024-06-25-22-42-17 Global epoch: 3, train_perceptual_mean, 1.1292007565498352\n",
      "\n",
      "2024-06-25-22-42-17 Global epoch: 3, train_perceptual_std, 0.00475442155805304\n",
      "\n",
      "2024-06-25-22-42-17 Global epoch: 3, train_codebook_mean, 0.01270685282846292\n",
      "\n",
      "2024-06-25-22-42-18 Global epoch: 3, train_codebook_std, 0.0002091369268314633\n",
      "\n",
      "2024-06-25-22-42-18 Global epoch: 3, train_total_mean, 0.08621794771816996\n",
      "\n",
      "2024-06-25-22-42-18 Global epoch: 3, train_total_std, 0.0009678008081166365\n",
      "\n",
      "<4> [0/18] Total loss: 0.08604157716035843\n",
      "<4> [1/18] Total loss: 0.08558408170938492\n",
      "<4> [2/18] Total loss: 0.08580894768238068\n",
      "<4> [3/18] Total loss: 0.0829276591539383\n",
      "<4> [4/18] Total loss: 0.08518077433109283\n",
      "<4> [5/18] Total loss: 0.08635681867599487\n",
      "<4> [6/18] Total loss: 0.0862116888165474\n",
      "<4> [7/18] Total loss: 0.08289006352424622\n",
      "<4> [8/18] Total loss: 0.0857996717095375\n",
      "<4> [9/18] Total loss: 0.08443659543991089\n",
      "<4> [10/18] Total loss: 0.08809122443199158\n",
      "<4> [11/18] Total loss: 0.0854748785495758\n",
      "<4> [12/18] Total loss: 0.08614735305309296\n",
      "<4> [13/18] Total loss: 0.08698639273643494\n",
      "<4> [14/18] Total loss: 0.0837903693318367\n",
      "<4> [15/18] Total loss: 0.08494409173727036\n",
      "<4> [16/18] Total loss: 0.08424193412065506\n",
      "<4> [17/18] Total loss: 0.08761125057935715\n",
      "2024-06-25-22-44-03 Global epoch: 4, train_reconL2_mean, 0.016776710852152772\n",
      "\n",
      "2024-06-25-22-44-03 Global epoch: 4, train_reconL2_std, 0.001037168611830358\n",
      "\n",
      "2024-06-25-22-44-03 Global epoch: 4, train_reconL1_mean, 0.11053829971286985\n",
      "\n",
      "2024-06-25-22-44-03 Global epoch: 4, train_reconL1_std, 0.003670521177558461\n",
      "\n",
      "2024-06-25-22-44-03 Global epoch: 4, train_perceptual_mean, 1.1289669275283813\n",
      "\n",
      "2024-06-25-22-44-03 Global epoch: 4, train_perceptual_std, 0.003853721815501522\n",
      "\n",
      "2024-06-25-22-44-03 Global epoch: 4, train_codebook_mean, 0.011947440707849132\n",
      "\n",
      "2024-06-25-22-44-03 Global epoch: 4, train_codebook_std, 0.00022394939690699382\n",
      "\n",
      "2024-06-25-22-44-03 Global epoch: 4, train_total_mean, 0.08547363181908925\n",
      "\n",
      "2024-06-25-22-44-03 Global epoch: 4, train_total_std, 0.0013942476248318444\n",
      "\n",
      "<5> [0/18] Total loss: 0.087362140417099\n",
      "<5> [1/18] Total loss: 0.08635889738798141\n",
      "<5> [2/18] Total loss: 0.0870966836810112\n",
      "<5> [3/18] Total loss: 0.09024397283792496\n",
      "<5> [4/18] Total loss: 0.08464617282152176\n",
      "<5> [5/18] Total loss: 0.08331279456615448\n",
      "<5> [6/18] Total loss: 0.08713839203119278\n",
      "<5> [7/18] Total loss: 0.08510322123765945\n",
      "<5> [8/18] Total loss: 0.08444216102361679\n",
      "<5> [9/18] Total loss: 0.08545303344726562\n",
      "<5> [10/18] Total loss: 0.08603033423423767\n",
      "<5> [11/18] Total loss: 0.08092372119426727\n",
      "<5> [12/18] Total loss: 0.08611747622489929\n",
      "<5> [13/18] Total loss: 0.08709849417209625\n",
      "<5> [14/18] Total loss: 0.08416558802127838\n",
      "<5> [15/18] Total loss: 0.08801106363534927\n",
      "<5> [16/18] Total loss: 0.08627573400735855\n",
      "<5> [17/18] Total loss: 0.08619805425405502\n",
      "2024-06-25-22-45-45 Global epoch: 5, train_reconL2_mean, 0.01714984379294846\n",
      "\n",
      "2024-06-25-22-45-45 Global epoch: 5, train_reconL2_std, 0.0013669969039008245\n",
      "\n",
      "2024-06-25-22-45-45 Global epoch: 5, train_reconL1_mean, 0.11069473417268859\n",
      "\n",
      "2024-06-25-22-45-45 Global epoch: 5, train_reconL1_std, 0.005069745068842467\n",
      "\n",
      "2024-06-25-22-45-45 Global epoch: 5, train_perceptual_mean, 1.1310951775974698\n",
      "\n",
      "2024-06-25-22-45-45 Global epoch: 5, train_perceptual_std, 0.004476106787246654\n",
      "\n",
      "2024-06-25-22-45-45 Global epoch: 5, train_codebook_mean, 0.011135856620967388\n",
      "\n",
      "2024-06-25-22-45-45 Global epoch: 5, train_codebook_std, 0.0002413917788909215\n",
      "\n",
      "2024-06-25-22-45-45 Global epoch: 5, train_total_mean, 0.08588766306638718\n",
      "\n",
      "2024-06-25-22-45-45 Global epoch: 5, train_total_std, 0.0019630747132025274\n",
      "\n",
      "<6> [0/18] Total loss: 0.08592290431261063\n",
      "<6> [1/18] Total loss: 0.0848381370306015\n",
      "<6> [2/18] Total loss: 0.08511680364608765\n",
      "<6> [3/18] Total loss: 0.08366456627845764\n",
      "<6> [4/18] Total loss: 0.08424070477485657\n",
      "<6> [5/18] Total loss: 0.08292126655578613\n",
      "<6> [6/18] Total loss: 0.08395969122648239\n",
      "<6> [7/18] Total loss: 0.0861571729183197\n",
      "<6> [8/18] Total loss: 0.08597394078969955\n",
      "<6> [9/18] Total loss: 0.08779299259185791\n",
      "<6> [10/18] Total loss: 0.0861654132604599\n",
      "<6> [11/18] Total loss: 0.08512508124113083\n",
      "<6> [12/18] Total loss: 0.08770716190338135\n",
      "<6> [13/18] Total loss: 0.08939280360937119\n",
      "<6> [14/18] Total loss: 0.0890733152627945\n",
      "<6> [15/18] Total loss: 0.086038738489151\n",
      "<6> [16/18] Total loss: 0.0856948271393776\n",
      "<6> [17/18] Total loss: 0.0847686380147934\n",
      "2024-06-25-22-47-23 Global epoch: 6, train_reconL2_mean, 0.016965998026231926\n",
      "\n",
      "2024-06-25-22-47-23 Global epoch: 6, train_reconL2_std, 0.0011289421116054321\n",
      "\n",
      "2024-06-25-22-47-23 Global epoch: 6, train_reconL1_mean, 0.11108019575476646\n",
      "\n",
      "2024-06-25-22-47-23 Global epoch: 6, train_reconL1_std, 0.0047506609606787625\n",
      "\n",
      "2024-06-25-22-47-23 Global epoch: 6, train_perceptual_mean, 1.1341608497831557\n",
      "\n",
      "2024-06-25-22-47-23 Global epoch: 6, train_perceptual_std, 0.004882894541643455\n",
      "\n",
      "2024-06-25-22-47-23 Global epoch: 6, train_codebook_mean, 0.010265029552910063\n",
      "\n",
      "2024-06-25-22-47-23 Global epoch: 6, train_codebook_std, 0.0002578858128579716\n",
      "\n",
      "2024-06-25-22-47-23 Global epoch: 6, train_total_mean, 0.08580856439140108\n",
      "\n",
      "2024-06-25-22-47-23 Global epoch: 6, train_total_std, 0.0017188787660344699\n",
      "\n",
      "<7> [0/18] Total loss: 0.08431940525770187\n",
      "<7> [1/18] Total loss: 0.08591233193874359\n",
      "<7> [2/18] Total loss: 0.08485402911901474\n",
      "<7> [3/18] Total loss: 0.08557549864053726\n",
      "<7> [4/18] Total loss: 0.08388669788837433\n",
      "<7> [5/18] Total loss: 0.08430833369493484\n",
      "<7> [6/18] Total loss: 0.08743775635957718\n",
      "<7> [7/18] Total loss: 0.0854329913854599\n",
      "<7> [8/18] Total loss: 0.08778168261051178\n",
      "<7> [9/18] Total loss: 0.08799976110458374\n",
      "<7> [10/18] Total loss: 0.08783931285142899\n",
      "<7> [11/18] Total loss: 0.08629674464464188\n",
      "<7> [12/18] Total loss: 0.08941650390625\n",
      "<7> [13/18] Total loss: 0.0853816345334053\n",
      "<7> [14/18] Total loss: 0.087025947868824\n",
      "<7> [15/18] Total loss: 0.08591105043888092\n",
      "<7> [16/18] Total loss: 0.08555462211370468\n",
      "<7> [17/18] Total loss: 0.08582331240177155\n",
      "2024-06-25-22-49-03 Global epoch: 7, train_reconL2_mean, 0.01733618105451266\n",
      "\n",
      "2024-06-25-22-49-03 Global epoch: 7, train_reconL2_std, 0.0011110440554467616\n",
      "\n",
      "2024-06-25-22-49-03 Global epoch: 7, train_reconL1_mean, 0.11164874542090628\n",
      "\n",
      "2024-06-25-22-49-03 Global epoch: 7, train_reconL1_std, 0.0035792040999051127\n",
      "\n",
      "2024-06-25-22-49-03 Global epoch: 7, train_perceptual_mean, 1.1342640452914767\n",
      "\n",
      "2024-06-25-22-49-03 Global epoch: 7, train_perceptual_std, 0.0042675908587259635\n",
      "\n",
      "2024-06-25-22-49-03 Global epoch: 7, train_codebook_mean, 0.009389410364545055\n",
      "\n",
      "2024-06-25-22-49-03 Global epoch: 7, train_codebook_std, 0.00026815073289583174\n",
      "\n",
      "2024-06-25-22-49-03 Global epoch: 7, train_total_mean, 0.08615320093101925\n",
      "\n",
      "2024-06-25-22-49-03 Global epoch: 7, train_total_std, 0.0014454716794881515\n",
      "\n",
      "<8> [0/18] Total loss: 0.08556418120861053\n",
      "<8> [1/18] Total loss: 0.08662024140357971\n",
      "<8> [2/18] Total loss: 0.08643457293510437\n",
      "<8> [3/18] Total loss: 0.08881299197673798\n",
      "<8> [4/18] Total loss: 0.08355815708637238\n",
      "<8> [5/18] Total loss: 0.08632081001996994\n",
      "<8> [6/18] Total loss: 0.08285093307495117\n",
      "<8> [7/18] Total loss: 0.08682439476251602\n",
      "<8> [8/18] Total loss: 0.08583749830722809\n",
      "<8> [9/18] Total loss: 0.08338825404644012\n",
      "<8> [10/18] Total loss: 0.08302795141935349\n",
      "<8> [11/18] Total loss: 0.08640135079622269\n",
      "<8> [12/18] Total loss: 0.08499623835086823\n",
      "<8> [13/18] Total loss: 0.08644616603851318\n",
      "<8> [14/18] Total loss: 0.08510642498731613\n",
      "<8> [15/18] Total loss: 0.08627135306596756\n",
      "<8> [16/18] Total loss: 0.08462147414684296\n",
      "<8> [17/18] Total loss: 0.0861445963382721\n",
      "2024-06-25-22-50-42 Global epoch: 8, train_reconL2_mean, 0.01703507960256603\n",
      "\n",
      "2024-06-25-22-50-42 Global epoch: 8, train_reconL2_std, 0.000988669058270233\n",
      "\n",
      "2024-06-25-22-50-42 Global epoch: 8, train_reconL1_mean, 0.10978829943471485\n",
      "\n",
      "2024-06-25-22-50-42 Global epoch: 8, train_reconL1_std, 0.0037145469475584727\n",
      "\n",
      "2024-06-25-22-50-42 Global epoch: 8, train_perceptual_mean, 1.1330198778046503\n",
      "\n",
      "2024-06-25-22-50-42 Global epoch: 8, train_perceptual_std, 0.0055202411318587994\n",
      "\n",
      "2024-06-25-22-50-42 Global epoch: 8, train_codebook_mean, 0.00847740016049809\n",
      "\n",
      "2024-06-25-22-50-42 Global epoch: 8, train_codebook_std, 0.0002667425628952754\n",
      "\n",
      "2024-06-25-22-50-42 Global epoch: 8, train_total_mean, 0.08551264388693704\n",
      "\n",
      "2024-06-25-22-50-42 Global epoch: 8, train_total_std, 0.0015074744021907945\n",
      "\n",
      "<9> [0/18] Total loss: 0.08663326501846313\n",
      "<9> [1/18] Total loss: 0.08636441081762314\n",
      "<9> [2/18] Total loss: 0.08433530479669571\n",
      "<9> [3/18] Total loss: 0.08364138752222061\n",
      "<9> [4/18] Total loss: 0.08903965353965759\n",
      "<9> [5/18] Total loss: 0.08419302105903625\n",
      "<9> [6/18] Total loss: 0.08632678538560867\n",
      "<9> [7/18] Total loss: 0.08523108065128326\n",
      "<9> [8/18] Total loss: 0.08412939310073853\n",
      "<9> [9/18] Total loss: 0.08737701177597046\n",
      "<9> [10/18] Total loss: 0.08554614335298538\n",
      "<9> [11/18] Total loss: 0.08556897938251495\n",
      "<9> [12/18] Total loss: 0.08605777472257614\n",
      "<9> [13/18] Total loss: 0.087288498878479\n",
      "<9> [14/18] Total loss: 0.08742927014827728\n",
      "<9> [15/18] Total loss: 0.08776461333036423\n",
      "<9> [16/18] Total loss: 0.08640175312757492\n",
      "<9> [17/18] Total loss: 0.08433568477630615\n",
      "2024-06-25-22-52-17 Global epoch: 9, train_reconL2_mean, 0.017232449156128697\n",
      "\n",
      "2024-06-25-22-52-17 Global epoch: 9, train_reconL2_std, 0.0010126142780138869\n",
      "\n",
      "2024-06-25-22-52-17 Global epoch: 9, train_reconL1_mean, 0.11209299994839562\n",
      "\n",
      "2024-06-25-22-52-17 Global epoch: 9, train_reconL1_std, 0.0034138347038413022\n",
      "\n",
      "2024-06-25-22-52-17 Global epoch: 9, train_perceptual_mean, 1.1357400748464797\n",
      "\n",
      "2024-06-25-22-52-17 Global epoch: 9, train_perceptual_std, 0.004825694381165307\n",
      "\n",
      "2024-06-25-22-52-17 Global epoch: 9, train_codebook_mean, 0.007525804219767451\n",
      "\n",
      "2024-06-25-22-52-17 Global epoch: 9, train_codebook_std, 0.00028125381580157687\n",
      "\n",
      "2024-06-25-22-52-17 Global epoch: 9, train_total_mean, 0.08598133507702085\n",
      "\n",
      "2024-06-25-22-52-17 Global epoch: 9, train_total_std, 0.0014453602345769834\n",
      "\n",
      "<10> [0/18] Total loss: 0.0847211480140686\n",
      "<10> [1/18] Total loss: 0.08341924101114273\n",
      "<10> [2/18] Total loss: 0.08595739305019379\n",
      "<10> [3/18] Total loss: 0.08489174395799637\n",
      "<10> [4/18] Total loss: 0.08657869696617126\n",
      "<10> [5/18] Total loss: 0.0836503729224205\n",
      "<10> [6/18] Total loss: 0.08306840062141418\n",
      "<10> [7/18] Total loss: 0.08326789736747742\n",
      "<10> [8/18] Total loss: 0.0813068374991417\n",
      "<10> [9/18] Total loss: 0.08266513794660568\n",
      "<10> [10/18] Total loss: 0.09181308001279831\n",
      "<10> [11/18] Total loss: 0.09371983259916306\n",
      "<10> [12/18] Total loss: 0.08557917922735214\n",
      "<10> [13/18] Total loss: 0.08435481786727905\n",
      "<10> [14/18] Total loss: 0.08436501771211624\n",
      "<10> [15/18] Total loss: 0.08266432583332062\n",
      "<10> [16/18] Total loss: 0.08602996170520782\n",
      "<10> [17/18] Total loss: 0.08765663951635361\n",
      "2024-06-25-22-54-03 Global epoch: 10, train_reconL2_mean, 0.017073247116059065\n",
      "\n",
      "2024-06-25-22-54-03 Global epoch: 10, train_reconL2_std, 0.002232201930892767\n",
      "\n",
      "2024-06-25-22-54-03 Global epoch: 10, train_reconL1_mean, 0.10924222982592052\n",
      "\n",
      "2024-06-25-22-54-03 Global epoch: 10, train_reconL1_std, 0.0065867175928854575\n",
      "\n",
      "2024-06-25-22-54-03 Global epoch: 10, train_perceptual_mean, 1.1333125366104975\n",
      "\n",
      "2024-06-25-22-54-03 Global epoch: 10, train_perceptual_std, 0.005568556212430575\n",
      "\n",
      "2024-06-25-22-54-03 Global epoch: 10, train_codebook_mean, 0.006541105427054895\n",
      "\n",
      "2024-06-25-22-54-03 Global epoch: 10, train_codebook_std, 0.0002894235850973115\n",
      "\n",
      "2024-06-25-22-54-03 Global epoch: 10, train_total_mean, 0.08531720687945683\n",
      "\n",
      "2024-06-25-22-54-03 Global epoch: 10, train_total_std, 0.003064239592123084\n",
      "\n",
      "<11> [0/18] Total loss: 0.08432889729738235\n",
      "<11> [1/18] Total loss: 0.08308917284011841\n",
      "<11> [2/18] Total loss: 0.08430079370737076\n",
      "<11> [3/18] Total loss: 0.08960650116205215\n",
      "<11> [4/18] Total loss: 0.08632854372262955\n",
      "<11> [5/18] Total loss: 0.08851559460163116\n",
      "<11> [6/18] Total loss: 0.08545249700546265\n",
      "<11> [7/18] Total loss: 0.0821416899561882\n",
      "<11> [8/18] Total loss: 0.08535493165254593\n",
      "<11> [9/18] Total loss: 0.08554225414991379\n",
      "<11> [10/18] Total loss: 0.08418518304824829\n",
      "<11> [11/18] Total loss: 0.08699110150337219\n",
      "<11> [12/18] Total loss: 0.08941012620925903\n",
      "<11> [13/18] Total loss: 0.08754128217697144\n",
      "<11> [14/18] Total loss: 0.0871310755610466\n",
      "<11> [15/18] Total loss: 0.0861896350979805\n",
      "<11> [16/18] Total loss: 0.0871855691075325\n",
      "<11> [17/18] Total loss: 0.086450956761837\n",
      "2024-06-25-22-55-55 Global epoch: 11, train_reconL2_mean, 0.017464653071429994\n",
      "\n",
      "2024-06-25-22-55-55 Global epoch: 11, train_reconL2_std, 0.001420504987681179\n",
      "\n",
      "2024-06-25-22-55-55 Global epoch: 11, train_reconL1_mean, 0.11280342067281406\n",
      "\n",
      "2024-06-25-22-55-55 Global epoch: 11, train_reconL1_std, 0.005291415816458135\n",
      "\n",
      "2024-06-25-22-55-55 Global epoch: 11, train_perceptual_mean, 1.1360778278774686\n",
      "\n",
      "2024-06-25-22-55-55 Global epoch: 11, train_perceptual_std, 0.004476066063363561\n",
      "\n",
      "2024-06-25-22-55-55 Global epoch: 11, train_codebook_mean, 0.005481016873899434\n",
      "\n",
      "2024-06-25-22-55-55 Global epoch: 11, train_codebook_std, 0.00032897752319688565\n",
      "\n",
      "2024-06-25-22-55-55 Global epoch: 11, train_total_mean, 0.08609698919786347\n",
      "\n",
      "2024-06-25-22-55-55 Global epoch: 11, train_total_std, 0.0019782572111920033\n",
      "\n",
      "<12> [0/18] Total loss: 0.08679232746362686\n",
      "<12> [1/18] Total loss: 0.08545495569705963\n",
      "<12> [2/18] Total loss: 0.08637312054634094\n",
      "<12> [3/18] Total loss: 0.08738618344068527\n",
      "<12> [4/18] Total loss: 0.0858619287610054\n",
      "<12> [5/18] Total loss: 0.08591806143522263\n",
      "<12> [6/18] Total loss: 0.08314410597085953\n",
      "<12> [7/18] Total loss: 0.0842239186167717\n",
      "<12> [8/18] Total loss: 0.0842217206954956\n",
      "<12> [9/18] Total loss: 0.0861295759677887\n",
      "<12> [10/18] Total loss: 0.0861278846859932\n",
      "<12> [11/18] Total loss: 0.08962428569793701\n",
      "<12> [12/18] Total loss: 0.08385921269655228\n",
      "<12> [13/18] Total loss: 0.08928325772285461\n",
      "<12> [14/18] Total loss: 0.0837579220533371\n",
      "<12> [15/18] Total loss: 0.08677631616592407\n",
      "<12> [16/18] Total loss: 0.08428733050823212\n",
      "<12> [17/18] Total loss: 0.08326984941959381\n",
      "2024-06-25-22-57-43 Global epoch: 12, train_reconL2_mean, 0.01727904472500086\n",
      "\n",
      "2024-06-25-22-57-43 Global epoch: 12, train_reconL2_std, 0.001259753656237956\n",
      "\n",
      "2024-06-25-22-57-43 Global epoch: 12, train_reconL1_mean, 0.1115708744360341\n",
      "\n",
      "2024-06-25-22-57-43 Global epoch: 12, train_reconL1_std, 0.004358655457409237\n",
      "\n",
      "2024-06-25-22-57-43 Global epoch: 12, train_perceptual_mean, 1.1364330119556851\n",
      "\n",
      "2024-06-25-22-57-43 Global epoch: 12, train_perceptual_std, 0.004403249401643874\n",
      "\n",
      "2024-06-25-22-57-43 Global epoch: 12, train_codebook_mean, 0.0043621421532912385\n",
      "\n",
      "2024-06-25-22-57-43 Global epoch: 12, train_codebook_std, 0.00030483814277595906\n",
      "\n",
      "2024-06-25-22-57-43 Global epoch: 12, train_total_mean, 0.08569399764140447\n",
      "\n",
      "2024-06-25-22-57-43 Global epoch: 12, train_total_std, 0.001831008197453171\n",
      "\n",
      "<13> [0/18] Total loss: 0.08647856116294861\n",
      "<13> [1/18] Total loss: 0.08662580698728561\n",
      "<13> [2/18] Total loss: 0.08523979038000107\n",
      "<13> [3/18] Total loss: 0.08112406730651855\n",
      "<13> [4/18] Total loss: 0.08628023415803909\n",
      "<13> [5/18] Total loss: 0.08822111040353775\n",
      "<13> [6/18] Total loss: 0.08719590306282043\n",
      "<13> [7/18] Total loss: 0.08437298238277435\n",
      "<13> [8/18] Total loss: 0.08732724189758301\n",
      "<13> [9/18] Total loss: 0.08601602166891098\n",
      "<13> [10/18] Total loss: 0.0877363383769989\n",
      "<13> [11/18] Total loss: 0.08479903638362885\n",
      "<13> [12/18] Total loss: 0.08587523549795151\n",
      "<13> [13/18] Total loss: 0.08433958142995834\n",
      "<13> [14/18] Total loss: 0.08442720025777817\n",
      "<13> [15/18] Total loss: 0.08747262507677078\n",
      "<13> [16/18] Total loss: 0.08669775724411011\n",
      "<13> [17/18] Total loss: 0.08576042950153351\n",
      "2024-06-25-22-59-21 Global epoch: 13, train_reconL2_mean, 0.01739431545138359\n",
      "\n",
      "2024-06-25-22-59-21 Global epoch: 13, train_reconL2_std, 0.0011136821311868992\n",
      "\n",
      "2024-06-25-22-59-21 Global epoch: 13, train_reconL1_mean, 0.11181529445780648\n",
      "\n",
      "2024-06-25-22-59-21 Global epoch: 13, train_reconL1_std, 0.004559805405347109\n",
      "\n",
      "2024-06-25-22-59-21 Global epoch: 13, train_perceptual_mean, 1.1369823747211032\n",
      "\n",
      "2024-06-25-22-59-21 Global epoch: 13, train_perceptual_std, 0.0044297750045400736\n",
      "\n",
      "2024-06-25-22-59-21 Global epoch: 13, train_codebook_mean, 0.004633642888317506\n",
      "\n",
      "2024-06-25-22-59-21 Global epoch: 13, train_codebook_std, 0.0006624135970344814\n",
      "\n",
      "2024-06-25-22-59-21 Global epoch: 13, train_total_mean, 0.0858883290655083\n",
      "\n",
      "2024-06-25-22-59-21 Global epoch: 13, train_total_std, 0.0016332688856175938\n",
      "\n",
      "<14> [0/18] Total loss: 0.08573343604803085\n",
      "<14> [1/18] Total loss: 0.083890400826931\n",
      "<14> [2/18] Total loss: 0.08388879895210266\n",
      "<14> [3/18] Total loss: 0.08611604571342468\n",
      "<14> [4/18] Total loss: 0.08202740550041199\n",
      "<14> [5/18] Total loss: 0.08816225826740265\n",
      "<14> [6/18] Total loss: 0.08439818769693375\n",
      "<14> [7/18] Total loss: 0.08315365016460419\n",
      "<14> [8/18] Total loss: 0.08937554806470871\n",
      "<14> [9/18] Total loss: 0.08635672181844711\n",
      "<14> [10/18] Total loss: 0.08944138884544373\n",
      "<14> [11/18] Total loss: 0.08432121574878693\n",
      "<14> [12/18] Total loss: 0.08781908452510834\n",
      "<14> [13/18] Total loss: 0.08364611864089966\n",
      "<14> [14/18] Total loss: 0.08587513864040375\n",
      "<14> [15/18] Total loss: 0.0850517749786377\n",
      "<14> [16/18] Total loss: 0.0860116183757782\n",
      "<14> [17/18] Total loss: 0.08659227937459946\n",
      "2024-06-25-23-01-10 Global epoch: 14, train_reconL2_mean, 0.017257240186962817\n",
      "\n",
      "2024-06-25-23-01-10 Global epoch: 14, train_reconL2_std, 0.0013764681462198093\n",
      "\n",
      "2024-06-25-23-01-10 Global epoch: 14, train_reconL1_mean, 0.11068367668324047\n",
      "\n",
      "2024-06-25-23-01-10 Global epoch: 14, train_reconL1_std, 0.004955702823753979\n",
      "\n",
      "2024-06-25-23-01-10 Global epoch: 14, train_perceptual_mean, 1.1353209680981107\n",
      "\n",
      "2024-06-25-23-01-10 Global epoch: 14, train_perceptual_std, 0.003944924427091858\n",
      "\n",
      "2024-06-25-23-01-10 Global epoch: 14, train_codebook_mean, 0.005672918761976891\n",
      "\n",
      "2024-06-25-23-01-10 Global epoch: 14, train_codebook_std, 0.0011613170706583438\n",
      "\n",
      "2024-06-25-23-01-10 Global epoch: 14, train_total_mean, 0.08565894845459196\n",
      "\n",
      "2024-06-25-23-01-10 Global epoch: 14, train_total_std, 0.0020319847218174935\n",
      "\n",
      "<15> [0/18] Total loss: 0.08641012012958527\n",
      "<15> [1/18] Total loss: 0.08514495939016342\n",
      "<15> [2/18] Total loss: 0.08651608973741531\n",
      "<15> [3/18] Total loss: 0.08939157426357269\n",
      "<15> [4/18] Total loss: 0.08417822420597076\n",
      "<15> [5/18] Total loss: 0.08664639294147491\n",
      "<15> [6/18] Total loss: 0.08334758132696152\n",
      "<15> [7/18] Total loss: 0.08469334244728088\n",
      "<15> [8/18] Total loss: 0.08412916958332062\n",
      "<15> [9/18] Total loss: 0.08961129188537598\n",
      "<15> [10/18] Total loss: 0.08895522356033325\n",
      "<15> [11/18] Total loss: 0.08887125551700592\n",
      "<15> [12/18] Total loss: 0.08323125541210175\n",
      "<15> [13/18] Total loss: 0.08926720917224884\n",
      "<15> [14/18] Total loss: 0.08620039373636246\n",
      "<15> [15/18] Total loss: 0.08997246623039246\n",
      "<15> [16/18] Total loss: 0.0862145945429802\n",
      "<15> [17/18] Total loss: 0.08694665133953094\n",
      "2024-06-25-23-02-56 Global epoch: 15, train_reconL2_mean, 0.017549273144039843\n",
      "\n",
      "2024-06-25-23-02-56 Global epoch: 15, train_reconL2_std, 0.0014460071910914218\n",
      "\n",
      "2024-06-25-23-02-56 Global epoch: 15, train_reconL1_mean, 0.11240207983387841\n",
      "\n",
      "2024-06-25-23-02-56 Global epoch: 15, train_reconL1_std, 0.005692677088623093\n",
      "\n",
      "2024-06-25-23-02-56 Global epoch: 15, train_perceptual_mean, 1.138233694765303\n",
      "\n",
      "2024-06-25-23-02-56 Global epoch: 15, train_perceptual_std, 0.005286275630719079\n",
      "\n",
      "2024-06-25-23-02-56 Global epoch: 15, train_codebook_mean, 0.009503766790860228\n",
      "\n",
      "2024-06-25-23-02-56 Global epoch: 15, train_codebook_std, 0.0009678865042248005\n",
      "\n",
      "2024-06-25-23-02-56 Global epoch: 15, train_total_mean, 0.08665154419011539\n",
      "\n",
      "2024-06-25-23-02-56 Global epoch: 15, train_total_std, 0.0021874509247050934\n",
      "\n",
      "<16> [0/18] Total loss: 0.0910734012722969\n",
      "<16> [1/18] Total loss: 0.08610864728689194\n",
      "<16> [2/18] Total loss: 0.08683378994464874\n",
      "<16> [3/18] Total loss: 0.08862318843603134\n",
      "<16> [4/18] Total loss: 0.08401839435100555\n",
      "<16> [5/18] Total loss: 0.08459585905075073\n",
      "<16> [6/18] Total loss: 0.08013570308685303\n",
      "<16> [7/18] Total loss: 0.08914530277252197\n",
      "<16> [8/18] Total loss: 0.08759425580501556\n",
      "<16> [9/18] Total loss: 0.08776253461837769\n",
      "<16> [10/18] Total loss: 0.08796879649162292\n",
      "<16> [11/18] Total loss: 0.08633825182914734\n",
      "<16> [12/18] Total loss: 0.08877894282341003\n",
      "<16> [13/18] Total loss: 0.0889405682682991\n",
      "<16> [14/18] Total loss: 0.08531137555837631\n",
      "<16> [15/18] Total loss: 0.08531472831964493\n",
      "<16> [16/18] Total loss: 0.08507969975471497\n",
      "<16> [17/18] Total loss: 0.087271548807621\n",
      "2024-06-25-23-04-34 Global epoch: 16, train_reconL2_mean, 0.017505777792798147\n",
      "\n",
      "2024-06-25-23-04-34 Global epoch: 16, train_reconL2_std, 0.0015868239459527274\n",
      "\n",
      "2024-06-25-23-04-34 Global epoch: 16, train_reconL1_mean, 0.11267516886194547\n",
      "\n",
      "2024-06-25-23-04-34 Global epoch: 16, train_reconL1_std, 0.006284910016713887\n",
      "\n",
      "2024-06-25-23-04-34 Global epoch: 16, train_perceptual_mean, 1.1354484624332852\n",
      "\n",
      "2024-06-25-23-04-34 Global epoch: 16, train_perceptual_std, 0.006899746702745117\n",
      "\n",
      "2024-06-25-23-04-34 Global epoch: 16, train_codebook_mean, 0.011706691649225023\n",
      "\n",
      "2024-06-25-23-04-34 Global epoch: 16, train_codebook_std, 0.00040410254024004686\n",
      "\n",
      "2024-06-25-23-04-34 Global epoch: 16, train_total_mean, 0.08671638824873501\n",
      "\n",
      "2024-06-25-23-04-34 Global epoch: 16, train_total_std, 0.0024000786890597584\n",
      "\n",
      "<17> [0/18] Total loss: 0.08755502849817276\n",
      "<17> [1/18] Total loss: 0.08867548406124115\n",
      "<17> [2/18] Total loss: 0.0877256765961647\n",
      "<17> [3/18] Total loss: 0.08628470450639725\n",
      "<17> [4/18] Total loss: 0.08512551337480545\n",
      "<17> [5/18] Total loss: 0.0877140611410141\n",
      "<17> [6/18] Total loss: 0.08519590646028519\n",
      "<17> [7/18] Total loss: 0.08628351986408234\n",
      "<17> [8/18] Total loss: 0.08459387719631195\n",
      "<17> [9/18] Total loss: 0.08683907240629196\n",
      "<17> [10/18] Total loss: 0.08321176469326019\n",
      "<17> [11/18] Total loss: 0.08815072476863861\n",
      "<17> [12/18] Total loss: 0.08690015226602554\n",
      "<17> [13/18] Total loss: 0.08950270712375641\n",
      "<17> [14/18] Total loss: 0.08437896519899368\n",
      "<17> [15/18] Total loss: 0.08743822574615479\n",
      "<17> [16/18] Total loss: 0.08466538786888123\n",
      "<17> [17/18] Total loss: 0.08354959636926651\n",
      "2024-06-25-23-06-07 Global epoch: 17, train_reconL2_mean, 0.017212459507087868\n",
      "\n",
      "2024-06-25-23-06-07 Global epoch: 17, train_reconL2_std, 0.0011694974335490092\n",
      "\n",
      "2024-06-25-23-06-07 Global epoch: 17, train_reconL1_mean, 0.11393110826611519\n",
      "\n",
      "2024-06-25-23-06-07 Global epoch: 17, train_reconL1_std, 0.004687763666636998\n",
      "\n",
      "2024-06-25-23-06-07 Global epoch: 17, train_perceptual_mean, 1.1324145793914795\n",
      "\n",
      "2024-06-25-23-06-07 Global epoch: 17, train_perceptual_std, 0.004247184016141994\n",
      "\n",
      "2024-06-25-23-06-07 Global epoch: 17, train_codebook_mean, 0.010953871585014794\n",
      "\n",
      "2024-06-25-23-06-07 Global epoch: 17, train_codebook_std, 0.00045274044975455703\n",
      "\n",
      "2024-06-25-23-06-07 Global epoch: 17, train_total_mean, 0.08632168711887465\n",
      "\n",
      "2024-06-25-23-06-07 Global epoch: 17, train_total_std, 0.0017613849257098165\n",
      "\n",
      "<18> [0/18] Total loss: 0.08375070989131927\n",
      "<18> [1/18] Total loss: 0.08559954166412354\n",
      "<18> [2/18] Total loss: 0.08731233328580856\n",
      "<18> [3/18] Total loss: 0.08696319162845612\n",
      "<18> [4/18] Total loss: 0.08566216379404068\n",
      "<18> [5/18] Total loss: 0.08899899572134018\n",
      "<18> [6/18] Total loss: 0.08756012469530106\n",
      "<18> [7/18] Total loss: 0.08383534848690033\n",
      "<18> [8/18] Total loss: 0.08827731758356094\n",
      "<18> [9/18] Total loss: 0.08567675203084946\n",
      "<18> [10/18] Total loss: 0.0869760811328888\n",
      "<18> [11/18] Total loss: 0.0855836421251297\n",
      "<18> [12/18] Total loss: 0.08630380034446716\n",
      "<18> [13/18] Total loss: 0.08675695955753326\n",
      "<18> [14/18] Total loss: 0.08683415502309799\n",
      "<18> [15/18] Total loss: 0.08303602039813995\n",
      "<18> [16/18] Total loss: 0.08509916812181473\n",
      "<18> [17/18] Total loss: 0.08504673838615417\n",
      "2024-06-25-23-07-46 Global epoch: 18, train_reconL2_mean, 0.017353204285932913\n",
      "\n",
      "2024-06-25-23-07-46 Global epoch: 18, train_reconL2_std, 0.0011436541254668797\n",
      "\n",
      "2024-06-25-23-07-46 Global epoch: 18, train_reconL1_mean, 0.11086483548084895\n",
      "\n",
      "2024-06-25-23-07-46 Global epoch: 18, train_reconL1_std, 0.005090106432741308\n",
      "\n",
      "2024-06-25-23-07-46 Global epoch: 18, train_perceptual_mean, 1.1334182951185439\n",
      "\n",
      "2024-06-25-23-07-46 Global epoch: 18, train_perceptual_std, 0.0034456891404486133\n",
      "\n",
      "2024-06-25-23-07-46 Global epoch: 18, train_codebook_mean, 0.009601221471610997\n",
      "\n",
      "2024-06-25-23-07-46 Global epoch: 18, train_codebook_std, 0.0003270298839511969\n",
      "\n",
      "2024-06-25-23-07-46 Global epoch: 18, train_total_mean, 0.08607072465949589\n",
      "\n",
      "2024-06-25-23-07-46 Global epoch: 18, train_total_std, 0.0015328013331681108\n",
      "\n",
      "<19> [0/18] Total loss: 0.0855771005153656\n",
      "<19> [1/18] Total loss: 0.08453655242919922\n",
      "<19> [2/18] Total loss: 0.08394758403301239\n",
      "<19> [3/18] Total loss: 0.08657439053058624\n",
      "<19> [4/18] Total loss: 0.0872076228260994\n",
      "<19> [5/18] Total loss: 0.08735793083906174\n",
      "<19> [6/18] Total loss: 0.08522600680589676\n",
      "<19> [7/18] Total loss: 0.08375382423400879\n",
      "<19> [8/18] Total loss: 0.08709286153316498\n",
      "<19> [9/18] Total loss: 0.08738695085048676\n",
      "<19> [10/18] Total loss: 0.08666763454675674\n",
      "<19> [11/18] Total loss: 0.08411967754364014\n",
      "<19> [12/18] Total loss: 0.08462784439325333\n",
      "<19> [13/18] Total loss: 0.08189970254898071\n",
      "<19> [14/18] Total loss: 0.08344884216785431\n",
      "<19> [15/18] Total loss: 0.08086686581373215\n",
      "<19> [16/18] Total loss: 0.08282559365034103\n",
      "<19> [17/18] Total loss: 0.08147567510604858\n",
      "2024-06-25-23-09-25 Global epoch: 19, train_reconL2_mean, 0.01667994974801938\n",
      "\n",
      "2024-06-25-23-09-25 Global epoch: 19, train_reconL2_std, 0.0012744190056555374\n",
      "\n",
      "2024-06-25-23-09-25 Global epoch: 19, train_reconL1_mean, 0.10978779113954967\n",
      "\n",
      "2024-06-25-23-09-25 Global epoch: 19, train_reconL1_std, 0.005324446956664396\n",
      "\n",
      "2024-06-25-23-09-25 Global epoch: 19, train_perceptual_mean, 1.12395003106859\n",
      "\n",
      "2024-06-25-23-09-25 Global epoch: 19, train_perceptual_std, 0.00838737351424282\n",
      "\n",
      "2024-06-25-23-09-25 Global epoch: 19, train_codebook_mean, 0.008433603940324651\n",
      "\n",
      "2024-06-25-23-09-25 Global epoch: 19, train_codebook_std, 0.0003136634877083428\n",
      "\n",
      "2024-06-25-23-09-25 Global epoch: 19, train_total_mean, 0.08469959224263827\n",
      "\n",
      "2024-06-25-23-09-25 Global epoch: 19, train_total_std, 0.0020353663947558294\n",
      "\n",
      "<20> [0/18] Total loss: 0.08041661977767944\n",
      "<20> [1/18] Total loss: 0.08628202974796295\n",
      "<20> [2/18] Total loss: 0.08087696880102158\n",
      "<20> [3/18] Total loss: 0.08186415582895279\n",
      "<20> [4/18] Total loss: 0.08107686787843704\n",
      "<20> [5/18] Total loss: 0.08049242198467255\n",
      "<20> [6/18] Total loss: 0.0787946954369545\n",
      "<20> [7/18] Total loss: 0.08137911558151245\n",
      "<20> [8/18] Total loss: 0.08030248433351517\n",
      "<20> [9/18] Total loss: 0.07841136306524277\n",
      "<20> [10/18] Total loss: 0.0779748186469078\n",
      "<20> [11/18] Total loss: 0.07706326246261597\n",
      "<20> [12/18] Total loss: 0.07623231410980225\n",
      "<20> [13/18] Total loss: 0.07667778432369232\n",
      "<20> [14/18] Total loss: 0.07637582719326019\n",
      "<20> [15/18] Total loss: 0.07576369494199753\n",
      "<20> [16/18] Total loss: 0.0740915834903717\n",
      "<20> [17/18] Total loss: 0.07203441858291626\n",
      "2024-06-25-23-11-02 Global epoch: 20, train_reconL2_mean, 0.013490543597274356\n",
      "\n",
      "2024-06-25-23-11-02 Global epoch: 20, train_reconL2_std, 0.0019350989270497223\n",
      "\n",
      "2024-06-25-23-11-02 Global epoch: 20, train_reconL1_mean, 0.09531846601102087\n",
      "\n",
      "2024-06-25-23-11-02 Global epoch: 20, train_reconL1_std, 0.007904969477051521\n",
      "\n",
      "2024-06-25-23-11-02 Global epoch: 20, train_perceptual_mean, 1.0978897412618\n",
      "\n",
      "2024-06-25-23-11-02 Global epoch: 20, train_perceptual_std, 0.011272447891582868\n",
      "\n",
      "2024-06-25-23-11-02 Global epoch: 20, train_codebook_mean, 0.007559228196947111\n",
      "\n",
      "2024-06-25-23-11-02 Global epoch: 20, train_codebook_std, 0.0002188332158461878\n",
      "\n",
      "2024-06-25-23-11-02 Global epoch: 20, train_total_mean, 0.07867280145486195\n",
      "\n",
      "2024-06-25-23-11-02 Global epoch: 20, train_total_std, 0.0032227202372857103\n",
      "\n",
      "<20> [0/22] Total loss: 0.07120274007320404\n",
      "<20> [1/22] Total loss: 0.07435276359319687\n",
      "<20> [2/22] Total loss: 0.07519306987524033\n",
      "<20> [3/22] Total loss: 0.07258155941963196\n",
      "<20> [4/22] Total loss: 0.07105007022619247\n",
      "<20> [5/22] Total loss: 0.07350099831819534\n",
      "<20> [6/22] Total loss: 0.07371535897254944\n",
      "<20> [7/22] Total loss: 0.07127109915018082\n",
      "<20> [8/22] Total loss: 0.07367689162492752\n",
      "<20> [9/22] Total loss: 0.07459577918052673\n",
      "<20> [10/22] Total loss: 0.07153457403182983\n",
      "<20> [11/22] Total loss: 0.07381707429885864\n",
      "<20> [12/22] Total loss: 0.0703088790178299\n",
      "<20> [13/22] Total loss: 0.07234348356723785\n",
      "<20> [14/22] Total loss: 0.07124081999063492\n",
      "<20> [15/22] Total loss: 0.07450079917907715\n",
      "<20> [16/22] Total loss: 0.07098208367824554\n",
      "<20> [17/22] Total loss: 0.07274220138788223\n",
      "<20> [18/22] Total loss: 0.07587172836065292\n",
      "<20> [19/22] Total loss: 0.0694638341665268\n",
      "<20> [20/22] Total loss: 0.07542826980352402\n",
      "<20> [21/22] Total loss: 0.07938557863235474\n",
      "2024-06-25-23-12-09 Global epoch: 20, val_reconL2_mean, 0.010552979497746988\n",
      "\n",
      "2024-06-25-23-12-09 Global epoch: 20, val_reconL2_std, 0.0013317817703077843\n",
      "\n",
      "2024-06-25-23-12-09 Global epoch: 20, val_reconL1_mean, 0.07807969877665694\n",
      "\n",
      "2024-06-25-23-12-09 Global epoch: 20, val_reconL1_std, 0.0053589499301755945\n",
      "\n",
      "2024-06-25-23-12-09 Global epoch: 20, val_perceptual_mean, 1.0810258767821572\n",
      "\n",
      "2024-06-25-23-12-09 Global epoch: 20, val_perceptual_std, 0.00993116588814532\n",
      "\n",
      "2024-06-25-23-12-09 Global epoch: 20, val_codebook_mean, 0.007131961131976409\n",
      "\n",
      "2024-06-25-23-12-09 Global epoch: 20, val_codebook_std, 0.00013958303453765204\n",
      "\n",
      "2024-06-25-23-12-09 Global epoch: 20, val_total_mean, 0.07312543893402274\n",
      "\n",
      "2024-06-25-23-12-09 Global epoch: 20, val_total_std, 0.0022121003751661658\n",
      "\n",
      "<21> [0/18] Total loss: 0.07134738564491272\n",
      "<21> [1/18] Total loss: 0.07099227607250214\n",
      "<21> [2/18] Total loss: 0.0716300681233406\n",
      "<21> [3/18] Total loss: 0.07163897156715393\n",
      "<21> [4/18] Total loss: 0.07078073918819427\n",
      "<21> [5/18] Total loss: 0.0665641650557518\n",
      "<21> [6/18] Total loss: 0.0694536492228508\n",
      "<21> [7/18] Total loss: 0.11032642424106598\n",
      "<21> [8/18] Total loss: 0.0939188227057457\n",
      "<21> [9/18] Total loss: 0.08756464719772339\n",
      "<21> [10/18] Total loss: 0.09546997398138046\n",
      "<21> [11/18] Total loss: 0.09714077413082123\n",
      "<21> [12/18] Total loss: 0.09807059913873672\n",
      "<21> [13/18] Total loss: 0.09130604565143585\n",
      "<21> [14/18] Total loss: 0.0855960100889206\n",
      "<21> [15/18] Total loss: 0.08981841057538986\n",
      "<21> [16/18] Total loss: 0.09163552522659302\n",
      "<21> [17/18] Total loss: 0.08903425186872482\n",
      "2024-06-25-23-13-53 Global epoch: 21, train_reconL2_mean, 0.01750779974584778\n",
      "\n",
      "2024-06-25-23-13-53 Global epoch: 21, train_reconL2_std, 0.007809090596071676\n",
      "\n",
      "2024-06-25-23-13-53 Global epoch: 21, train_reconL1_mean, 0.10386286406881279\n",
      "\n",
      "2024-06-25-23-13-53 Global epoch: 21, train_reconL1_std, 0.028684153864412948\n",
      "\n",
      "2024-06-25-23-13-53 Global epoch: 21, train_perceptual_mean, 1.1209431290626526\n",
      "\n",
      "2024-06-25-23-13-53 Global epoch: 21, train_perceptual_std, 0.040564936925553394\n",
      "\n",
      "2024-06-25-23-13-53 Global epoch: 21, train_codebook_mean, 0.006303525064140558\n",
      "\n",
      "2024-06-25-23-13-53 Global epoch: 21, train_codebook_std, 0.0005782885853405892\n",
      "\n",
      "2024-06-25-23-13-53 Global epoch: 21, train_total_mean, 0.084571596648958\n",
      "\n",
      "2024-06-25-23-13-53 Global epoch: 21, train_total_std, 0.012470830507548478\n",
      "\n",
      "<22> [0/18] Total loss: 0.0894075259566307\n",
      "<22> [1/18] Total loss: 0.08879959583282471\n",
      "<22> [2/18] Total loss: 0.08833196759223938\n",
      "<22> [3/18] Total loss: 0.0847761332988739\n",
      "<22> [4/18] Total loss: 0.0855683833360672\n",
      "<22> [5/18] Total loss: 0.09019915759563446\n",
      "<22> [6/18] Total loss: 0.0848604142665863\n",
      "<22> [7/18] Total loss: 0.08605779707431793\n",
      "<22> [8/18] Total loss: 0.08779583126306534\n",
      "<22> [9/18] Total loss: 0.08510840684175491\n",
      "<22> [10/18] Total loss: 0.08525623381137848\n",
      "<22> [11/18] Total loss: 0.08832541853189468\n",
      "<22> [12/18] Total loss: 0.08562608063220978\n",
      "<22> [13/18] Total loss: 0.08653532713651657\n",
      "<22> [14/18] Total loss: 0.085581474006176\n",
      "<22> [15/18] Total loss: 0.08776247501373291\n",
      "<22> [16/18] Total loss: 0.08540742099285126\n",
      "<22> [17/18] Total loss: 0.08375754952430725\n",
      "2024-06-25-23-15-31 Global epoch: 22, train_reconL2_mean, 0.0179499215963814\n",
      "\n",
      "2024-06-25-23-15-31 Global epoch: 22, train_reconL2_std, 0.0011865844411521333\n",
      "\n",
      "2024-06-25-23-15-31 Global epoch: 22, train_reconL1_mean, 0.11244885995984077\n",
      "\n",
      "2024-06-25-23-15-31 Global epoch: 22, train_reconL1_std, 0.005257099972375464\n",
      "\n",
      "2024-06-25-23-15-31 Global epoch: 22, train_perceptual_mean, 1.1370258265071445\n",
      "\n",
      "2024-06-25-23-15-31 Global epoch: 22, train_perceptual_std, 0.008572859939312082\n",
      "\n",
      "2024-06-25-23-15-31 Global epoch: 22, train_codebook_mean, 0.0057374397034032475\n",
      "\n",
      "2024-06-25-23-15-31 Global epoch: 22, train_codebook_std, 4.515314718233136e-05\n",
      "\n",
      "2024-06-25-23-15-31 Global epoch: 22, train_total_mean, 0.0866198440392812\n",
      "\n",
      "2024-06-25-23-15-31 Global epoch: 22, train_total_std, 0.0017897656821366198\n",
      "\n",
      "<23> [0/18] Total loss: 0.08293527364730835\n",
      "<23> [1/18] Total loss: 0.09029363095760345\n",
      "<23> [2/18] Total loss: 0.08585953712463379\n",
      "<23> [3/18] Total loss: 0.08360596001148224\n",
      "<23> [4/18] Total loss: 0.08612110465765\n",
      "<23> [5/18] Total loss: 0.08528286963701248\n",
      "<23> [6/18] Total loss: 0.08530262857675552\n",
      "<23> [7/18] Total loss: 0.08391521871089935\n",
      "<23> [8/18] Total loss: 0.087129607796669\n",
      "<23> [9/18] Total loss: 0.08564191311597824\n",
      "<23> [10/18] Total loss: 0.08490956574678421\n",
      "<23> [11/18] Total loss: 0.09268803894519806\n",
      "<23> [12/18] Total loss: 0.08457739651203156\n",
      "<23> [13/18] Total loss: 0.08651833236217499\n",
      "<23> [14/18] Total loss: 0.07939581573009491\n",
      "<23> [15/18] Total loss: 0.07125444710254669\n",
      "<23> [16/18] Total loss: 0.07027103006839752\n",
      "<23> [17/18] Total loss: 0.07157497107982635\n",
      "2024-06-25-23-17-04 Global epoch: 23, train_reconL2_mean, 0.015935681708570983\n",
      "\n",
      "2024-06-25-23-17-04 Global epoch: 23, train_reconL2_std, 0.0035158644081014602\n",
      "\n",
      "2024-06-25-23-17-04 Global epoch: 23, train_reconL1_mean, 0.10509582526153988\n",
      "\n",
      "2024-06-25-23-17-04 Global epoch: 23, train_reconL1_std, 0.015126241626094206\n",
      "\n",
      "2024-06-25-23-17-04 Global epoch: 23, train_perceptual_mean, 1.1225257184770372\n",
      "\n",
      "2024-06-25-23-17-04 Global epoch: 23, train_perceptual_std, 0.023492917920098392\n",
      "\n",
      "2024-06-25-23-17-04 Global epoch: 23, train_codebook_mean, 0.006105237045428819\n",
      "\n",
      "2024-06-25-23-17-04 Global epoch: 23, train_codebook_std, 0.0006705684688866724\n",
      "\n",
      "2024-06-25-23-17-04 Global epoch: 23, train_total_mean, 0.0831820745435026\n",
      "\n",
      "2024-06-25-23-17-04 Global epoch: 23, train_total_std, 0.006065164830581631\n",
      "\n",
      "<24> [0/18] Total loss: 0.07125813513994217\n",
      "<24> [1/18] Total loss: 0.07235594838857651\n",
      "<24> [2/18] Total loss: 0.07034901529550552\n",
      "<24> [3/18] Total loss: 0.07037492841482162\n",
      "<24> [4/18] Total loss: 0.06693857163190842\n",
      "<24> [5/18] Total loss: 0.06844460964202881\n",
      "<24> [6/18] Total loss: 0.0706714317202568\n",
      "<24> [7/18] Total loss: 0.06657121330499649\n",
      "<24> [8/18] Total loss: 0.06453508138656616\n",
      "<24> [9/18] Total loss: 0.06732899695634842\n",
      "<24> [10/18] Total loss: 0.0646049752831459\n",
      "<24> [11/18] Total loss: 0.06717263907194138\n",
      "<24> [12/18] Total loss: 0.06383666396141052\n",
      "<24> [13/18] Total loss: 0.0659518614411354\n",
      "<24> [14/18] Total loss: 0.06518350541591644\n",
      "<24> [15/18] Total loss: 0.06492161005735397\n",
      "<24> [16/18] Total loss: 0.06169990822672844\n",
      "<24> [17/18] Total loss: 0.060937780886888504\n",
      "2024-06-25-23-18-42 Global epoch: 24, train_reconL2_mean, 0.007457459811121225\n",
      "\n",
      "2024-06-25-23-18-42 Global epoch: 24, train_reconL2_std, 0.001491037158489908\n",
      "\n",
      "2024-06-25-23-18-42 Global epoch: 24, train_reconL1_mean, 0.06049081765943103\n",
      "\n",
      "2024-06-25-23-18-42 Global epoch: 24, train_reconL1_std, 0.009647467278041583\n",
      "\n",
      "2024-06-25-23-18-42 Global epoch: 24, train_perceptual_mean, 1.0537174079153273\n",
      "\n",
      "2024-06-25-23-18-42 Global epoch: 24, train_perceptual_std, 0.017097672041156278\n",
      "\n",
      "2024-06-25-23-18-42 Global epoch: 24, train_codebook_mean, 0.006485253365503417\n",
      "\n",
      "2024-06-25-23-18-42 Global epoch: 24, train_codebook_std, 0.00010596659133484541\n",
      "\n",
      "2024-06-25-23-18-42 Global epoch: 24, train_total_mean, 0.06684093756808175\n",
      "\n",
      "2024-06-25-23-18-42 Global epoch: 24, train_total_std, 0.0031643728328528344\n",
      "\n",
      "<25> [0/18] Total loss: 0.0609387531876564\n",
      "<25> [1/18] Total loss: 0.06383414566516876\n",
      "<25> [2/18] Total loss: 0.06094827875494957\n",
      "<25> [3/18] Total loss: 0.060293424874544144\n",
      "<25> [4/18] Total loss: 0.061591241508722305\n",
      "<25> [5/18] Total loss: 0.059911444783210754\n",
      "<25> [6/18] Total loss: 0.06027177348732948\n",
      "<25> [7/18] Total loss: 0.060854893177747726\n",
      "<25> [8/18] Total loss: 0.06303637474775314\n",
      "<25> [9/18] Total loss: 0.061500124633312225\n",
      "<25> [10/18] Total loss: 0.06149826571345329\n",
      "<25> [11/18] Total loss: 0.06090100109577179\n",
      "<25> [12/18] Total loss: 0.060467418283224106\n",
      "<25> [13/18] Total loss: 0.06078735366463661\n",
      "<25> [14/18] Total loss: 0.06206442043185234\n",
      "<25> [15/18] Total loss: 0.061638567596673965\n",
      "<25> [16/18] Total loss: 0.0602111890912056\n",
      "<25> [17/18] Total loss: 0.06089792400598526\n",
      "2024-06-25-23-20-31 Global epoch: 25, train_reconL2_mean, 0.004865789242709677\n",
      "\n",
      "2024-06-25-23-20-31 Global epoch: 25, train_reconL2_std, 0.0005910028720709571\n",
      "\n",
      "2024-06-25-23-20-31 Global epoch: 25, train_reconL1_mean, 0.04560399614274502\n",
      "\n",
      "2024-06-25-23-20-31 Global epoch: 25, train_reconL1_std, 0.0021153573902416628\n",
      "\n",
      "2024-06-25-23-20-31 Global epoch: 25, train_perceptual_mean, 1.0229540997081332\n",
      "\n",
      "2024-06-25-23-20-31 Global epoch: 25, train_perceptual_std, 0.007916331573380635\n",
      "\n",
      "2024-06-25-23-20-31 Global epoch: 25, train_codebook_mean, 0.006286937044933438\n",
      "\n",
      "2024-06-25-23-20-31 Global epoch: 25, train_codebook_std, 7.746288111053234e-05\n",
      "\n",
      "2024-06-25-23-20-31 Global epoch: 25, train_total_mean, 0.06120258859462208\n",
      "\n",
      "2024-06-25-23-20-31 Global epoch: 25, train_total_std, 0.0009730383757623856\n",
      "\n",
      "<26> [0/18] Total loss: 0.06111367791891098\n",
      "<26> [1/18] Total loss: 0.06232988089323044\n",
      "<26> [2/18] Total loss: 0.06044686958193779\n",
      "<26> [3/18] Total loss: 0.061965253204107285\n",
      "<26> [4/18] Total loss: 0.06149260327219963\n",
      "<26> [5/18] Total loss: 0.06250482052564621\n",
      "<26> [6/18] Total loss: 0.06239116191864014\n",
      "<26> [7/18] Total loss: 0.06439018249511719\n",
      "<26> [8/18] Total loss: 0.058910343796014786\n",
      "<26> [9/18] Total loss: 0.0627656877040863\n",
      "<26> [10/18] Total loss: 0.06199235841631889\n",
      "<26> [11/18] Total loss: 0.062149349600076675\n",
      "<26> [12/18] Total loss: 0.06285981833934784\n",
      "<26> [13/18] Total loss: 0.06271595507860184\n",
      "<26> [14/18] Total loss: 0.06032472476363182\n",
      "<26> [15/18] Total loss: 0.06034195423126221\n",
      "<26> [16/18] Total loss: 0.06246161460876465\n",
      "<26> [17/18] Total loss: 0.059766385704278946\n",
      "2024-06-25-23-22-14 Global epoch: 26, train_reconL2_mean, 0.005117945088487532\n",
      "\n",
      "2024-06-25-23-22-14 Global epoch: 26, train_reconL2_std, 0.0008099657903278781\n",
      "\n",
      "2024-06-25-23-22-14 Global epoch: 26, train_reconL1_mean, 0.044178529332081475\n",
      "\n",
      "2024-06-25-23-22-14 Global epoch: 26, train_reconL1_std, 0.002963002607066081\n",
      "\n",
      "2024-06-25-23-22-14 Global epoch: 26, train_perceptual_mean, 1.031061377790239\n",
      "\n",
      "2024-06-25-23-22-14 Global epoch: 26, train_perceptual_std, 0.008610644215024098\n",
      "\n",
      "2024-06-25-23-22-14 Global epoch: 26, train_codebook_mean, 0.006290578102279041\n",
      "\n",
      "2024-06-25-23-22-14 Global epoch: 26, train_codebook_std, 0.00011191969934528966\n",
      "\n",
      "2024-06-25-23-22-14 Global epoch: 26, train_total_mean, 0.06171792455845409\n",
      "\n",
      "2024-06-25-23-22-14 Global epoch: 26, train_total_std, 0.0012999608267499408\n",
      "\n",
      "<27> [0/18] Total loss: 0.060684625059366226\n",
      "<27> [1/18] Total loss: 0.06538962572813034\n",
      "<27> [2/18] Total loss: 0.09271026402711868\n",
      "<27> [3/18] Total loss: 0.09520987421274185\n",
      "<27> [4/18] Total loss: 0.08480241149663925\n",
      "<27> [5/18] Total loss: 0.08830202370882034\n",
      "<27> [6/18] Total loss: 0.08875133842229843\n",
      "<27> [7/18] Total loss: 0.09330455958843231\n",
      "<27> [8/18] Total loss: 0.09544450789690018\n",
      "<27> [9/18] Total loss: 0.08420708775520325\n",
      "<27> [10/18] Total loss: 0.09029556810855865\n",
      "<27> [11/18] Total loss: 0.08636339008808136\n",
      "<27> [12/18] Total loss: 0.0882047489285469\n",
      "<27> [13/18] Total loss: 0.08356434106826782\n",
      "<27> [14/18] Total loss: 0.0873461589217186\n",
      "<27> [15/18] Total loss: 0.08232687413692474\n",
      "<27> [16/18] Total loss: 0.08432043343782425\n",
      "<27> [17/18] Total loss: 0.08315316587686539\n",
      "2024-06-25-23-23-51 Global epoch: 27, train_reconL2_mean, 0.01776010517237915\n",
      "\n",
      "2024-06-25-23-23-51 Global epoch: 27, train_reconL2_std, 0.005555156013412604\n",
      "\n",
      "2024-06-25-23-23-51 Global epoch: 27, train_reconL1_mean, 0.1084666612247626\n",
      "\n",
      "2024-06-25-23-23-51 Global epoch: 27, train_reconL1_std, 0.02317589238946596\n",
      "\n",
      "2024-06-25-23-23-51 Global epoch: 27, train_perceptual_mean, 1.1212872531678941\n",
      "\n",
      "2024-06-25-23-23-51 Global epoch: 27, train_perceptual_std, 0.028135381011131215\n",
      "\n",
      "2024-06-25-23-23-51 Global epoch: 27, train_codebook_mean, 0.005722537326316039\n",
      "\n",
      "2024-06-25-23-23-51 Global epoch: 27, train_codebook_std, 0.00045740915070230663\n",
      "\n",
      "2024-06-25-23-23-51 Global epoch: 27, train_total_mean, 0.08524338880346881\n",
      "\n",
      "2024-06-25-23-23-51 Global epoch: 27, train_total_std, 0.008821944979891354\n",
      "\n",
      "<28> [0/18] Total loss: 0.08754190057516098\n",
      "<28> [1/18] Total loss: 0.08653882890939713\n",
      "<28> [2/18] Total loss: 0.08283405750989914\n",
      "<28> [3/18] Total loss: 0.08366646617650986\n",
      "<28> [4/18] Total loss: 0.08264078199863434\n",
      "<28> [5/18] Total loss: 0.07777734845876694\n",
      "<28> [6/18] Total loss: 0.0819363221526146\n",
      "<28> [7/18] Total loss: 0.07851307094097137\n",
      "<28> [8/18] Total loss: 0.08022651821374893\n",
      "<28> [9/18] Total loss: 0.07743269950151443\n",
      "<28> [10/18] Total loss: 0.07134274393320084\n",
      "<28> [11/18] Total loss: 0.07187734544277191\n",
      "<28> [12/18] Total loss: 0.07204294204711914\n",
      "<28> [13/18] Total loss: 0.06994303315877914\n",
      "<28> [14/18] Total loss: 0.06819307804107666\n",
      "<28> [15/18] Total loss: 0.06812334060668945\n",
      "<28> [16/18] Total loss: 0.06858612596988678\n",
      "<28> [17/18] Total loss: 0.06965072453022003\n",
      "2024-06-25-23-25-38 Global epoch: 28, train_reconL2_mean, 0.012173877563327551\n",
      "\n",
      "2024-06-25-23-25-38 Global epoch: 28, train_reconL2_std, 0.0035735079467658667\n",
      "\n",
      "2024-06-25-23-25-38 Global epoch: 28, train_reconL1_mean, 0.08982715631524722\n",
      "\n",
      "2024-06-25-23-25-38 Global epoch: 28, train_reconL1_std, 0.01593004261218978\n",
      "\n",
      "2024-06-25-23-25-38 Global epoch: 28, train_perceptual_mean, 1.0947106149461534\n",
      "\n",
      "2024-06-25-23-25-38 Global epoch: 28, train_perceptual_std, 0.028688766267783092\n",
      "\n",
      "2024-06-25-23-25-38 Global epoch: 28, train_codebook_mean, 0.0071161553884545965\n",
      "\n",
      "2024-06-25-23-25-38 Global epoch: 28, train_codebook_std, 0.0006325466184384717\n",
      "\n",
      "2024-06-25-23-25-38 Global epoch: 28, train_total_mean, 0.07660374045372009\n",
      "\n",
      "2024-06-25-23-25-38 Global epoch: 28, train_total_std, 0.006503123000028418\n",
      "\n",
      "<29> [0/18] Total loss: 0.0701633095741272\n",
      "<29> [1/18] Total loss: 0.0696067065000534\n",
      "<29> [2/18] Total loss: 0.07144225388765335\n",
      "<29> [3/18] Total loss: 0.06574835628271103\n",
      "<29> [4/18] Total loss: 0.06316948682069778\n",
      "<29> [5/18] Total loss: 0.06454798579216003\n",
      "<29> [6/18] Total loss: 0.06324885785579681\n",
      "<29> [7/18] Total loss: 0.06239987164735794\n",
      "<29> [8/18] Total loss: 0.060796529054641724\n",
      "<29> [9/18] Total loss: 0.06189475208520889\n",
      "<29> [10/18] Total loss: 0.06203465536236763\n",
      "<29> [11/18] Total loss: 0.06082760542631149\n",
      "<29> [12/18] Total loss: 0.06118260324001312\n",
      "<29> [13/18] Total loss: 0.06164625287055969\n",
      "<29> [14/18] Total loss: 0.059786006808280945\n",
      "<29> [15/18] Total loss: 0.0601302906870842\n",
      "<29> [16/18] Total loss: 0.061483580619096756\n",
      "<29> [17/18] Total loss: 0.06171149015426636\n",
      "2024-06-25-23-27-19 Global epoch: 29, train_reconL2_mean, 0.005949583344368471\n",
      "\n",
      "2024-06-25-23-27-19 Global epoch: 29, train_reconL2_std, 0.001414837983273036\n",
      "\n",
      "2024-06-25-23-27-19 Global epoch: 29, train_reconL1_mean, 0.051409329598148666\n",
      "\n",
      "2024-06-25-23-27-19 Global epoch: 29, train_reconL1_std, 0.009394928638548825\n",
      "\n",
      "2024-06-25-23-27-19 Global epoch: 29, train_perceptual_mean, 1.0346206890212164\n",
      "\n",
      "2024-06-25-23-27-19 Global epoch: 29, train_perceptual_std, 0.022815396720152516\n",
      "\n",
      "2024-06-25-23-27-19 Global epoch: 29, train_codebook_mean, 0.006129263615649607\n",
      "\n",
      "2024-06-25-23-27-19 Global epoch: 29, train_codebook_std, 0.00025275134865258625\n",
      "\n",
      "2024-06-25-23-27-19 Global epoch: 29, train_total_mean, 0.06343447748157713\n",
      "\n",
      "2024-06-25-23-27-19 Global epoch: 29, train_total_std, 0.0034369258115161923\n",
      "\n",
      "<30> [0/18] Total loss: 0.06376660615205765\n",
      "<30> [1/18] Total loss: 0.06450892984867096\n",
      "<30> [2/18] Total loss: 0.061462849378585815\n",
      "<30> [3/18] Total loss: 0.06938904523849487\n",
      "<30> [4/18] Total loss: 0.06491467356681824\n",
      "<30> [5/18] Total loss: 0.06311316043138504\n",
      "<30> [6/18] Total loss: 0.06043737381696701\n",
      "<30> [7/18] Total loss: 0.060650259256362915\n",
      "<30> [8/18] Total loss: 0.06025952473282814\n",
      "<30> [9/18] Total loss: 0.060562048107385635\n",
      "<30> [10/18] Total loss: 0.06152523681521416\n",
      "<30> [11/18] Total loss: 0.06145628169178963\n",
      "<30> [12/18] Total loss: 0.06155472621321678\n",
      "<30> [13/18] Total loss: 0.06221911683678627\n",
      "<30> [14/18] Total loss: 0.060281768441200256\n",
      "<30> [15/18] Total loss: 0.06328929960727692\n",
      "<30> [16/18] Total loss: 0.058976270258426666\n",
      "<30> [17/18] Total loss: 0.05961619317531586\n",
      "2024-06-25-23-28-58 Global epoch: 30, train_reconL2_mean, 0.005279331519785855\n",
      "\n",
      "2024-06-25-23-28-58 Global epoch: 30, train_reconL2_std, 0.0012806313137928552\n",
      "\n",
      "2024-06-25-23-28-58 Global epoch: 30, train_reconL1_mean, 0.048114683065149516\n",
      "\n",
      "2024-06-25-23-28-58 Global epoch: 30, train_reconL1_std, 0.005674377422615484\n",
      "\n",
      "2024-06-25-23-28-58 Global epoch: 30, train_perceptual_mean, 1.023916396829817\n",
      "\n",
      "2024-06-25-23-28-58 Global epoch: 30, train_perceptual_std, 0.017258989889573348\n",
      "\n",
      "2024-06-25-23-28-58 Global epoch: 30, train_codebook_mean, 0.008235661571638452\n",
      "\n",
      "2024-06-25-23-28-58 Global epoch: 30, train_codebook_std, 0.0008547633578575223\n",
      "\n",
      "2024-06-25-23-28-58 Global epoch: 30, train_total_mean, 0.06211018686493238\n",
      "\n",
      "2024-06-25-23-28-58 Global epoch: 30, train_total_std, 0.002396594979390032\n",
      "\n",
      "<31> [0/18] Total loss: 0.0601343959569931\n",
      "<31> [1/18] Total loss: 0.06229748576879501\n",
      "<31> [2/18] Total loss: 0.060874976217746735\n",
      "<31> [3/18] Total loss: 0.06112559884786606\n",
      "<31> [4/18] Total loss: 0.060631465166807175\n",
      "<31> [5/18] Total loss: 0.06140447035431862\n",
      "<31> [6/18] Total loss: 0.06117350608110428\n",
      "<31> [7/18] Total loss: 0.060429371893405914\n",
      "<31> [8/18] Total loss: 0.06015331670641899\n",
      "<31> [9/18] Total loss: 0.061289552599191666\n",
      "<31> [10/18] Total loss: 0.059512268751859665\n",
      "<31> [11/18] Total loss: 0.05982816591858864\n",
      "<31> [12/18] Total loss: 0.06022300198674202\n",
      "<31> [13/18] Total loss: 0.05854276940226555\n",
      "<31> [14/18] Total loss: 0.06016770005226135\n",
      "<31> [15/18] Total loss: 0.0602802112698555\n",
      "<31> [16/18] Total loss: 0.061577703803777695\n",
      "<31> [17/18] Total loss: 0.06065663322806358\n",
      "2024-06-25-23-30-49 Global epoch: 31, train_reconL2_mean, 0.004534007774458991\n",
      "\n",
      "2024-06-25-23-30-49 Global epoch: 31, train_reconL2_std, 0.0004398768459244162\n",
      "\n",
      "2024-06-25-23-30-49 Global epoch: 31, train_reconL1_mean, 0.043097067831291094\n",
      "\n",
      "2024-06-25-23-30-49 Global epoch: 31, train_reconL1_std, 0.002527479007708033\n",
      "\n",
      "2024-06-25-23-30-49 Global epoch: 31, train_perceptual_mean, 1.019323296017117\n",
      "\n",
      "2024-06-25-23-30-49 Global epoch: 31, train_perceptual_std, 0.008875618387764305\n",
      "\n",
      "2024-06-25-23-30-49 Global epoch: 31, train_codebook_mean, 0.007624861422098345\n",
      "\n",
      "2024-06-25-23-30-49 Global epoch: 31, train_codebook_std, 0.0005684840219952666\n",
      "\n",
      "2024-06-25-23-30-49 Global epoch: 31, train_total_mean, 0.06057236633367009\n",
      "\n",
      "2024-06-25-23-30-49 Global epoch: 31, train_total_std, 0.0008339675250888858\n",
      "\n",
      "<32> [0/18] Total loss: 0.05962986499071121\n",
      "<32> [1/18] Total loss: 0.06286643445491791\n",
      "<32> [2/18] Total loss: 0.060478631407022476\n",
      "<32> [3/18] Total loss: 0.06079443544149399\n",
      "<32> [4/18] Total loss: 0.059845078736543655\n",
      "<32> [5/18] Total loss: 0.059993695467710495\n",
      "<32> [6/18] Total loss: 0.06038038060069084\n",
      "<32> [7/18] Total loss: 0.0591026209294796\n",
      "<32> [8/18] Total loss: 0.059898048639297485\n",
      "<32> [9/18] Total loss: 0.05932198092341423\n",
      "<32> [10/18] Total loss: 0.061952318996191025\n",
      "<32> [11/18] Total loss: 0.05953158065676689\n",
      "<32> [12/18] Total loss: 0.06100870296359062\n",
      "<32> [13/18] Total loss: 0.061781737953424454\n",
      "<32> [14/18] Total loss: 0.05993833765387535\n",
      "<32> [15/18] Total loss: 0.061425138264894485\n",
      "<32> [16/18] Total loss: 0.06201187148690224\n",
      "<32> [17/18] Total loss: 0.06078995391726494\n",
      "2024-06-25-23-32-27 Global epoch: 32, train_reconL2_mean, 0.004781111557450559\n",
      "\n",
      "2024-06-25-23-32-27 Global epoch: 32, train_reconL2_std, 0.0006359033995378423\n",
      "\n",
      "2024-06-25-23-32-27 Global epoch: 32, train_reconL1_mean, 0.04322851076722145\n",
      "\n",
      "2024-06-25-23-32-27 Global epoch: 32, train_reconL1_std, 0.0023581934035638973\n",
      "\n",
      "2024-06-25-23-32-27 Global epoch: 32, train_perceptual_mean, 1.0164177980687883\n",
      "\n",
      "2024-06-25-23-32-27 Global epoch: 32, train_perceptual_std, 0.010749450980294789\n",
      "\n",
      "2024-06-25-23-32-27 Global epoch: 32, train_codebook_mean, 0.006724145936055316\n",
      "\n",
      "2024-06-25-23-32-27 Global epoch: 32, train_codebook_std, 0.0003194828801154152\n",
      "\n",
      "2024-06-25-23-32-27 Global epoch: 32, train_total_mean, 0.06059726741578844\n",
      "\n",
      "2024-06-25-23-32-27 Global epoch: 32, train_total_std, 0.0010318857533930035\n",
      "\n",
      "<33> [0/18] Total loss: 0.06038797274231911\n",
      "<33> [1/18] Total loss: 0.060340385884046555\n",
      "<33> [2/18] Total loss: 0.06158016249537468\n",
      "<33> [3/18] Total loss: 0.060788825154304504\n",
      "<33> [4/18] Total loss: 0.06063155084848404\n",
      "<33> [5/18] Total loss: 0.06011364981532097\n",
      "<33> [6/18] Total loss: 0.06085081025958061\n",
      "<33> [7/18] Total loss: 0.06043292209506035\n",
      "<33> [8/18] Total loss: 0.05936453118920326\n",
      "<33> [9/18] Total loss: 0.059768978506326675\n",
      "<33> [10/18] Total loss: 0.06005554646253586\n",
      "<33> [11/18] Total loss: 0.05976073071360588\n",
      "<33> [12/18] Total loss: 0.061391301453113556\n",
      "<33> [13/18] Total loss: 0.060690298676490784\n",
      "<33> [14/18] Total loss: 0.059696849435567856\n",
      "<33> [15/18] Total loss: 0.060732152312994\n",
      "<33> [16/18] Total loss: 0.06202949211001396\n",
      "<33> [17/18] Total loss: 0.06075254827737808\n",
      "2024-06-25-23-34-05 Global epoch: 33, train_reconL2_mean, 0.004649188964524203\n",
      "\n",
      "2024-06-25-23-34-05 Global epoch: 33, train_reconL2_std, 0.00040701479671980816\n",
      "\n",
      "2024-06-25-23-34-05 Global epoch: 33, train_reconL1_mean, 0.042960690748360425\n",
      "\n",
      "2024-06-25-23-34-05 Global epoch: 33, train_reconL1_std, 0.0016893500010900747\n",
      "\n",
      "2024-06-25-23-34-05 Global epoch: 33, train_perceptual_mean, 1.0188573797543843\n",
      "\n",
      "2024-06-25-23-34-05 Global epoch: 33, train_perceptual_std, 0.008041033041319048\n",
      "\n",
      "2024-06-25-23-34-05 Global epoch: 33, train_codebook_mean, 0.006323557838590609\n",
      "\n",
      "2024-06-25-23-34-05 Global epoch: 33, train_codebook_std, 0.00023142747267881653\n",
      "\n",
      "2024-06-25-23-34-05 Global epoch: 33, train_total_mean, 0.06052048380176226\n",
      "\n",
      "2024-06-25-23-34-05 Global epoch: 33, train_total_std, 0.0006697938568101071\n",
      "\n",
      "<34> [0/18] Total loss: 0.05933738872408867\n",
      "<34> [1/18] Total loss: 0.06032745912671089\n",
      "<34> [2/18] Total loss: 0.05872222036123276\n",
      "<34> [3/18] Total loss: 0.06132069230079651\n",
      "<34> [4/18] Total loss: 0.05936397612094879\n",
      "<34> [5/18] Total loss: 0.06281855702400208\n",
      "<34> [6/18] Total loss: 0.061134498566389084\n",
      "<34> [7/18] Total loss: 0.05908774584531784\n",
      "<34> [8/18] Total loss: 0.06033359467983246\n",
      "<34> [9/18] Total loss: 0.06131930276751518\n",
      "<34> [10/18] Total loss: 0.06081194803118706\n",
      "<34> [11/18] Total loss: 0.059098981320858\n",
      "<34> [12/18] Total loss: 0.060466691851615906\n",
      "<34> [13/18] Total loss: 0.06001373380422592\n",
      "<34> [14/18] Total loss: 0.058938611298799515\n",
      "<34> [15/18] Total loss: 0.06077536195516586\n",
      "<34> [16/18] Total loss: 0.059094734489917755\n",
      "<34> [17/18] Total loss: 0.060836490243673325\n",
      "2024-06-25-23-35-43 Global epoch: 34, train_reconL2_mean, 0.0045616619625232285\n",
      "\n",
      "2024-06-25-23-35-43 Global epoch: 34, train_reconL2_std, 0.0007601868660717719\n",
      "\n",
      "2024-06-25-23-35-43 Global epoch: 34, train_reconL1_mean, 0.042317953374650746\n",
      "\n",
      "2024-06-25-23-35-43 Global epoch: 34, train_reconL1_std, 0.0024285398120998903\n",
      "\n",
      "2024-06-25-23-35-43 Global epoch: 34, train_perceptual_mean, 1.01639637682173\n",
      "\n",
      "2024-06-25-23-35-43 Global epoch: 34, train_perceptual_std, 0.009155616630555368\n",
      "\n",
      "2024-06-25-23-35-43 Global epoch: 34, train_codebook_mean, 0.005979440485437711\n",
      "\n",
      "2024-06-25-23-35-43 Global epoch: 34, train_codebook_std, 0.00033460264050274723\n",
      "\n",
      "2024-06-25-23-35-43 Global epoch: 34, train_total_mean, 0.06021122158401542\n",
      "\n",
      "2024-06-25-23-35-43 Global epoch: 34, train_total_std, 0.001063958486437932\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Error #179: Function Can't open SHM failed:\n",
      "OMP: System error #0: Success\n",
      "OMP: Error #179: Function Can't open SHM failed:\n",
      "OMP: System error #0: Success\n",
      "OMP: Error #179: Function Can't open SHM failed:\n",
      "OMP: System error #0: Success\n",
      "OMP: Error #179: Function Can't open SHM failed:\n",
      "OMP: System error #0: Success\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 17472, 17473, 17474) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1161\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1161\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 17473) is killed by signal: Aborted. ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [45], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m epoch_loss_train \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreconL2\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreconL1\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m      9\u001b[0m }\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx_batch, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# print x size\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# print(\"x size is \", x.size())\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1357\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1357\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1360\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1306\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m# Fetches data from `self._data_queue`.\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# If `pin_memory=True`, we also need check if `pin_memory_thread` had\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;66;03m# died at timeouts.\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1306\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1308\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1174\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1173\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pids_str)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 17472, 17473, 17474) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "for idx_epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    epoch_loss_train = {\n",
    "        \"reconL2\": [],\n",
    "        \"reconL1\": [],\n",
    "        \"perceptual\": [],\n",
    "        \"codebook\": [],\n",
    "        \"total\": [],\n",
    "    }\n",
    "\n",
    "    for idx_batch, batch in enumerate(train_loader):\n",
    "        x = batch[\"image\"].to(device)\n",
    "        # print x size\n",
    "        # print(\"x size is \", x.size())\n",
    "        xrec, cb_loss = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_dist = preceptual_model(x, xrec)\n",
    "        reconL2_loss = F.mse_loss(x, xrec)\n",
    "        reconL1_loss = F.l1_loss(x, xrec)\n",
    "        perceptual_loss = total_dist\n",
    "        codebook_loss = cb_loss\n",
    "        total_loss = loss_weights[\"reconL2\"] * reconL2_loss + \\\n",
    "                        loss_weights[\"reconL1\"] * reconL1_loss + \\\n",
    "                        loss_weights[\"perceptual\"] * perceptual_loss + \\\n",
    "                        loss_weights[\"codebook\"] * codebook_loss\n",
    "        epoch_loss_train[\"reconL2\"].append(reconL2_loss.item())\n",
    "        epoch_loss_train[\"reconL1\"].append(reconL1_loss.item())\n",
    "        epoch_loss_train[\"perceptual\"].append(perceptual_loss.item())\n",
    "        epoch_loss_train[\"codebook\"].append(codebook_loss.item())\n",
    "        epoch_loss_train[\"total\"].append(total_loss.item())\n",
    "        print(f\"<{idx_epoch}> [{idx_batch}/{num_train_batch}] Total loss: {total_loss.item()}\")\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    for key in epoch_loss_train.keys():\n",
    "        epoch_loss_train[key] = np.asanyarray(epoch_loss_train[key])\n",
    "        logger.log(idx_epoch, f\"train_{key}_mean\", epoch_loss_train[key].mean())\n",
    "        logger.log(idx_epoch, f\"train_{key}_std\", epoch_loss_train[key].std())\n",
    "\n",
    "    # validation\n",
    "    if idx_epoch % val_per_epoch == 0:\n",
    "        model.eval()\n",
    "        epoch_loss_val = {\n",
    "            \"reconL2\": [],\n",
    "            \"reconL1\": [],\n",
    "            \"perceptual\": [],\n",
    "            \"codebook\": [],\n",
    "            \"total\": [],\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            for idx_batch, batch in enumerate(val_loader):\n",
    "                x = batch[\"image\"].to(device)\n",
    "                xrec, cb_loss = model(x)\n",
    "                total_dist = preceptual_model(x, xrec)\n",
    "                reconL2_loss = F.mse_loss(x, xrec)\n",
    "                reconL1_loss = F.l1_loss(x, xrec)\n",
    "                perceptual_loss = total_dist\n",
    "                codebook_loss = cb_loss\n",
    "                total_loss = loss_weights[\"reconL2\"] * reconL2_loss + \\\n",
    "                                loss_weights[\"reconL1\"] * reconL1_loss + \\\n",
    "                                loss_weights[\"perceptual\"] * perceptual_loss + \\\n",
    "                                loss_weights[\"codebook\"] * codebook_loss\n",
    "                epoch_loss_val[\"reconL2\"].append(reconL2_loss.item())\n",
    "                epoch_loss_val[\"reconL1\"].append(reconL1_loss.item())\n",
    "                epoch_loss_val[\"perceptual\"].append(perceptual_loss.item())\n",
    "                epoch_loss_val[\"codebook\"].append(codebook_loss.item())\n",
    "                epoch_loss_val[\"total\"].append(total_loss.item())\n",
    "                print(f\"<{idx_epoch}> [{idx_batch}/{num_val_batch}] Total loss: {total_loss.item()}\")\n",
    "        \n",
    "        for key in epoch_loss_val.keys():\n",
    "            epoch_loss_val[key] = np.asanyarray(epoch_loss_val[key])\n",
    "            logger.log(idx_epoch, f\"val_{key}_mean\", epoch_loss_val[key].mean())\n",
    "            logger.log(idx_epoch, f\"val_{key}_std\", epoch_loss_val[key].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total ct files are  1172\n",
      "[713]/[1172] tsv1_ct/s0864.nii.gz has error: CRC check failed 0x5ab25329 != 0x84f031a9\n",
      "[787]/[1172] tsv1_ct/s0955.nii.gz shape is (149, 149, 29) the pixel dimension is (149, 149, 29)\n",
      "mv tsv1_ct/s0955.nii.gz tsv1_ct_small/s0955.nii.gz\n",
      "[797]/[1172] tsv1_ct/s0968.nii.gz shape is (193, 193, 59) the pixel dimension is (193, 193, 59)\n",
      "mv tsv1_ct/s0968.nii.gz tsv1_ct_small/s0968.nii.gz\n",
      "[870]/[1172] tsv1_ct/s1047.nii.gz shape is (129, 129, 62) the pixel dimension is (129, 129, 62)\n",
      "mv tsv1_ct/s1047.nii.gz tsv1_ct_small/s1047.nii.gz\n",
      "[871]/[1172] tsv1_ct/s1048.nii.gz shape is (235, 235, 33) the pixel dimension is (235, 235, 33)\n",
      "mv tsv1_ct/s1048.nii.gz tsv1_ct_small/s1048.nii.gz\n",
      "[886]/[1172] tsv1_ct/s1065.nii.gz shape is (319, 319, 54) the pixel dimension is (319, 319, 54)\n",
      "mv tsv1_ct/s1065.nii.gz tsv1_ct_small/s1065.nii.gz\n",
      "[920]/[1172] tsv1_ct/s1109.nii.gz shape is (267, 267, 60) the pixel dimension is (267, 267, 60)\n",
      "mv tsv1_ct/s1109.nii.gz tsv1_ct_small/s1109.nii.gz\n",
      "[953]/[1172] tsv1_ct/s1147.nii.gz shape is (51, 101, 150) the pixel dimension is (51, 101, 150)\n",
      "mv tsv1_ct/s1147.nii.gz tsv1_ct_small/s1147.nii.gz\n",
      "[1009]/[1172] tsv1_ct/s1218.nii.gz shape is (249, 249, 45) the pixel dimension is (249, 249, 45)\n",
      "mv tsv1_ct/s1218.nii.gz tsv1_ct_small/s1218.nii.gz\n",
      "[1012]/[1172] tsv1_ct/s1222.nii.gz shape is (264, 264, 61) the pixel dimension is (264, 264, 61)\n",
      "mv tsv1_ct/s1222.nii.gz tsv1_ct_small/s1222.nii.gz\n",
      "[1038]/[1172] tsv1_ct/s1250.nii.gz shape is (219, 219, 59) the pixel dimension is (219, 219, 59)\n",
      "mv tsv1_ct/s1250.nii.gz tsv1_ct_small/s1250.nii.gz\n",
      "[1059]/[1172] tsv1_ct/s1275.nii.gz shape is (263, 263, 39) the pixel dimension is (263, 263, 39)\n",
      "mv tsv1_ct/s1275.nii.gz tsv1_ct_small/s1275.nii.gz\n",
      "[1063]/[1172] tsv1_ct/s1279.nii.gz shape is (172, 172, 57) the pixel dimension is (172, 172, 57)\n",
      "mv tsv1_ct/s1279.nii.gz tsv1_ct_small/s1279.nii.gz\n",
      "[1068]/[1172] tsv1_ct/s1286.nii.gz shape is (206, 206, 60) the pixel dimension is (206, 206, 60)\n",
      "mv tsv1_ct/s1286.nii.gz tsv1_ct_small/s1286.nii.gz\n",
      "[1072]/[1172] tsv1_ct/s1290.nii.gz shape is (176, 176, 32) the pixel dimension is (176, 176, 32)\n",
      "mv tsv1_ct/s1290.nii.gz tsv1_ct_small/s1290.nii.gz\n",
      "[1094]/[1172] tsv1_ct/s1315.nii.gz shape is (181, 181, 58) the pixel dimension is (181, 181, 58)\n",
      "mv tsv1_ct/s1315.nii.gz tsv1_ct_small/s1315.nii.gz\n",
      "[1095]/[1172] tsv1_ct/s1316.nii.gz shape is (256, 256, 43) the pixel dimension is (256, 256, 43)\n",
      "mv tsv1_ct/s1316.nii.gz tsv1_ct_small/s1316.nii.gz\n",
      "[1096]/[1172] tsv1_ct/s1317.nii.gz shape is (213, 213, 48) the pixel dimension is (213, 213, 48)\n",
      "mv tsv1_ct/s1317.nii.gz tsv1_ct_small/s1317.nii.gz\n",
      "[1105]/[1172] tsv1_ct/s1328.nii.gz shape is (247, 247, 47) the pixel dimension is (247, 247, 47)\n",
      "mv tsv1_ct/s1328.nii.gz tsv1_ct_small/s1328.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# # show all the data shape in tsv1_ct\n",
    "\n",
    "# import os\n",
    "# import glob\n",
    "# import nibabel as nib\n",
    "# ct_file_list = sorted(glob.glob(\"tsv1_ct/*.nii.gz\"))\n",
    "# print(\"total ct files are \", len(ct_file_list))\n",
    "# len_ct = len(ct_file_list)\n",
    "\n",
    "# for idx_ct, ct_path in enumerate(ct_file_list):\n",
    "#     ct_file = nib.load(ct_path)\n",
    "#     ct_filename = ct_path.split(\"/\")[-1]\n",
    "#     try:\n",
    "#         ct_data = ct_file.get_fdata()\n",
    "#         shapes = ct_data.shape\n",
    "#         # if any shapes is less than 64, we need to move it to tsv1_ct_small\n",
    "#         if shapes[0] < 64 or shapes[1] < 64 or shapes[2] < 64:\n",
    "#             print(f\"[{idx_ct+1}]/[{len_ct}] {ct_path} shape is {ct_data.shape} the pixel dimension is {shapes}\")\n",
    "#             cmd = f\"mv {ct_path} tsv1_ct_small/{ct_filename}\"\n",
    "#             print(cmd)\n",
    "#             os.system(cmd)\n",
    "#     except Exception as e:\n",
    "#         print(f\"[{idx_ct+1}]/[{len_ct}] {ct_path} has error: {e}\")\n",
    "#     # print(f\"{ct_path} shape is {ct_data.shape} the pixel dimension is {}\")\n",
    "#     # cmd = f\"mv {ct_file} tsv1_ct_small/{ct_filename}\"\n",
    "#     # print(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
